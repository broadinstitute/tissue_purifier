{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "casual-might",
   "metadata": {},
   "source": [
    "# PROCESS TESTIS_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-momentum",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "therapeutic-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(root_path, \"src\")\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-maker",
   "metadata": {},
   "source": [
    "# Read csv files into anndata objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "drawn-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.io_utils.read import anndata_from_expression_csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "incident-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "sick1\n",
      "location_file ---> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick1/BeadLocationsForR_T4_Trimmed.csv\n",
      "cell_type_file --> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick1/sick_1.csv\n",
      "expression_file -> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick1/MappedDGEForR_T4_Trimmed.csv\n",
      "creating anndata object with the counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving anndata to file ./anndata_sick1.h5ad\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "wt2\n",
      "location_file ---> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt2/BeadLocationsForR_Puck24_Trimmed_cleaned.csv\n",
      "cell_type_file --> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt2/wt_2.csv\n",
      "expression_file -> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt2/MappedDGEForR_Puck24_Trimmed.csv\n",
      "creating anndata object with the counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving anndata to file ./anndata_wt2.h5ad\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "wt3\n",
      "location_file ---> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt3/BeadLocationsForR_Normal_Puck7_Trimmed.csv\n",
      "cell_type_file --> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt3/wt_3.csv\n",
      "expression_file -> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt3/MappedDGEForR_Normal_Puck7_Trimmed.csv\n",
      "creating anndata object with the counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving anndata to file ./anndata_wt3.h5ad\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "sick2\n",
      "location_file ---> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick2/BeadLocationsForR_Diabetes_Puck10_Trimmed.csv\n",
      "cell_type_file --> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick2/sick_2.csv\n",
      "expression_file -> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick2/MappedDGEForR_Diabetes_Puck10_Trimmed.csv\n",
      "creating anndata object with the counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving anndata to file ./anndata_sick2.h5ad\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "sick3\n",
      "location_file ---> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick3/BeadLocationsForR_Diabetes_Puck11_Trimmed.csv\n",
      "cell_type_file --> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick3/sick_3.csv\n",
      "expression_file -> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/sick3/MappedDGEForR_Diabetes_Puck11_Trimmed.csv\n",
      "creating anndata object with the counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving anndata to file ./anndata_sick3.h5ad\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "wt1\n",
      "location_file ---> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt1/BeadLocationsForR_T3_Trimmed.csv\n",
      "cell_type_file --> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt1/wt_1.csv\n",
      "expression_file -> /Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED/wt1/MappedDGEForR_T3_Trimmed.csv\n",
      "creating anndata object with the counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving anndata to file ./anndata_wt1.h5ad\n"
     ]
    }
   ],
   "source": [
    "root_data_dir = '/Users/ldalessi/REPOS/ML_for_slideseq/TESTIS_data/PROCESSED'\n",
    "\n",
    "dir_tmp = os.listdir(root_data_dir)\n",
    "anndata_fnames = []\n",
    "n_rows = None\n",
    "\n",
    "for my_dir in dir_tmp:\n",
    "    \n",
    "    path = os.path.join(root_data_dir, my_dir)\n",
    "    files = os.listdir(path)\n",
    "       \n",
    "    for file in files:\n",
    "        if file.startswith(\"sick_\"):\n",
    "            cell_type_file = os.path.join(root_data_dir, my_dir, file)\n",
    "        elif file.startswith(\"wt_\"):\n",
    "            cell_type_file = os.path.join(root_data_dir, my_dir, file)\n",
    "        elif file.startswith(\"Mapped\"):\n",
    "            expression_file = os.path.join(root_data_dir, my_dir, file)\n",
    "        elif file.startswith(\"BeadLocation\"):\n",
    "            location_file = os.path.join(root_data_dir, my_dir, file)\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(\"---\")\n",
    "    print(\"---\")\n",
    "    print(\"---\")\n",
    "    print(my_dir)\n",
    "    print(\"location_file --->\", location_file)\n",
    "    print(\"cell_type_file -->\", cell_type_file)\n",
    "    print(\"expression_file ->\", expression_file)\n",
    "    \n",
    "    # create the anndata object\n",
    "    print(\"creating anndata object with the counts\")\n",
    "    anndata = anndata_from_expression_csv(expression_file, observation_key='barcode', top_n_rows=n_rows)\n",
    "    \n",
    "    # get the metadata and add to the obs dataframe\n",
    "    locations_df = pd.read_csv(location_file, usecols=[\"barcode\", \"x\", \"y\"])\n",
    "    cell_types_df = pd.read_csv(cell_type_file, usecols=[\"barcode\", \"cell_type\"])\n",
    "    metadata_df = locations_df.merge(cell_types_df).set_index(\"barcode\")\n",
    "    \n",
    "    # add the metadata into the anndata.obs padaframe. Note that I do not change the order of the entries.\n",
    "    anndata.obs = anndata.obs.join(metadata_df)\n",
    "\n",
    "    # save the anndata object to disk\n",
    "    filename = \"./anndata_\"+my_dir+\".h5ad\"\n",
    "    print(\"saving anndata to file\", filename)\n",
    "    anndata.write(filename=filename, compression=None)\n",
    "    anndata_fnames.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-atlanta",
   "metadata": {},
   "source": [
    "## Test that I can read anndata and make sparse images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "whole-binary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./anndata_sick1.h5ad',\n",
       " './anndata_wt2.h5ad',\n",
       " './anndata_wt3.h5ad',\n",
       " './anndata_sick2.h5ad',\n",
       " './anndata_sick3.h5ad',\n",
       " './anndata_wt1.h5ad']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anndata import read_h5ad\n",
    "from tissue_purifier.data_utils.sparse_image import SparseImage\n",
    "\n",
    "anndata_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "tropical-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 27194 × 24420\n",
      "    obs: 'x', 'y', 'cell_type'\n",
      "AnnData object with n_obs × n_vars = 33059 × 23741\n",
      "    obs: 'x', 'y', 'cell_type'\n",
      "AnnData object with n_obs × n_vars = 39206 × 23705\n",
      "    obs: 'x', 'y', 'cell_type'\n",
      "AnnData object with n_obs × n_vars = 42776 × 24263\n",
      "    obs: 'x', 'y', 'cell_type'\n",
      "AnnData object with n_obs × n_vars = 33441 × 23514\n",
      "    obs: 'x', 'y', 'cell_type'\n",
      "AnnData object with n_obs × n_vars = 31659 × 24450\n",
      "    obs: 'x', 'y', 'cell_type'\n"
     ]
    }
   ],
   "source": [
    "for filename in anndata_fnames:\n",
    "    anndata = read_h5ad(filename)\n",
    "    print(anndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "improved-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 31659\n",
      "mean and median spacing 15.622264926052864, 15.420071793081707\n",
      "The dense shape of the image is -> torch.Size([9, 1221, 1221])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 31653     3]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 31627    16]\n"
     ]
    }
   ],
   "source": [
    "sp = SparseImage.from_anndata(anndata=anndata, x_key=\"x\", y_key=\"y\", category_key=\"cell_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "analyzed-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ...,    8,    8,    8],\n",
       "                       [  10,   17,   17,  ..., 1179, 1183, 1197],\n",
       "                       [ 652,  657,  673,  ...,  716,  470,  586]]),\n",
       "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "       size=(9, 1221, 1221), nnz=31656, dtype=torch.int32,\n",
       "       layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-collar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
