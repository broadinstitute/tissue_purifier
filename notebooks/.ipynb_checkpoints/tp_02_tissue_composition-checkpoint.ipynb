{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cognitive-trade",
   "metadata": {},
   "source": [
    "# Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-egyptian",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "declared-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(root_path, \"src\")\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incoming-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tissue_purifier.data_utils.datamodule import SlideSeqKidneyDM, SlideSeqTestisDM\n",
    "from tissue_purifier.plot_utils.plot_images import show_raw_all_channels, show_raw_one_channel\n",
    "from tissue_purifier.plot_utils.plot_misc import plot_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dominican-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline/e56af8ab-fcfc-4bd5-bb36-57f40c78e4e8\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "-----> running datamodule init\n",
      "-----> running datamodule prepare_data\n",
      "untar data\n",
      "number of elements ---> 31659\n",
      "mean and median spacing 15.622264926052864, 15.420071793081707\n",
      "The dense shape of the image is -> torch.Size([9, 1178, 1178])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 31649     5]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 31629    15]\n",
      "number of elements ---> 33059\n",
      "mean and median spacing 15.358030584634598, 15.508166323067783\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 855])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 33033    13]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 32973    43]\n",
      "number of elements ---> 39206\n",
      "mean and median spacing 15.535967840319682, 15.438280914030202\n",
      "The dense shape of the image is -> torch.Size([9, 1179, 1180])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 39204     1]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 39202     2]\n",
      "number of elements ---> 27194\n",
      "mean and median spacing 16.12433160571037, 15.591954248205585\n",
      "The dense shape of the image is -> torch.Size([9, 1176, 1180])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 27190     2]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 27174    10]\n",
      "number of elements ---> 42776\n",
      "mean and median spacing 15.424869146306138, 15.42998109176031\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1180])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 42772     2]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 42764     6]\n",
      "number of elements ---> 33441\n",
      "mean and median spacing 15.479421424523398, 15.47439133436206\n",
      "The dense shape of the image is -> torch.Size([9, 1164, 1165])\n",
      "Occupacy (zero, single, double, ...) of voxels in 3D sparse array -> [    0 33433     4]\n",
      "Occupacy (zero, single, double, ...) of voxels  in 2D sparse array (summed over category) -> [    0 33423     9]\n",
      "-----> running datamodule setup. stage ->None\n",
      "All cat_to_codes dictionaries are idnetical {'ES': 0, 'Endothelial': 1, 'Leydig': 2, 'Macrophage': 3, 'Myoid': 4, 'RS': 5, 'SPC': 6, 'SPG': 7, 'Sertoli': 8}\n",
      "train dataset length 6\n",
      "train dataset device -> cuda:0\n",
      "test dataset length 120\n",
      "test dataset device -> cuda:0\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "NEPTUNE_TOKEN = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjZTkyYmJiYi0wN2E1LTRkY2YtOWU3Ny1kNjhjYmM3ZTVkNWEifQ==\"\n",
    "NEPTUNE_PROJECT = \"cellarium/tissue-purifier\"\n",
    "\n",
    "dataset = \"testis_dataset\" \n",
    "logging_mode = \"offline\" # or \"async\"\n",
    "\n",
    "if dataset == \"kidney_dataset\":\n",
    "    DM = SlideSeqKidneyDM\n",
    "elif dataset == \"testis_dataset\":\n",
    "    DM = SlideSeqTestisDM\n",
    "else:\n",
    "    raise Exception()\n",
    "\n",
    "exp: neptune.run.Run = neptune.init(project=NEPTUNE_PROJECT,\n",
    "                                    api_token=NEPTUNE_TOKEN,\n",
    "                                    mode=logging_mode,\n",
    "                                    tags=[\"validation\", dataset])\n",
    "    \n",
    "config_dict = DM.get_default_params()\n",
    "    \n",
    "config_dict['n_crops_for_tissue_test'] = 20\n",
    "config_dict['dropout_range'] = [0.0, 0.2]\n",
    "config_dict['cohort'] = 'all'\n",
    "\n",
    "# print(config_dict)\n",
    "\n",
    "dm = DM(**config_dict)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-cutting",
   "metadata": {},
   "source": [
    "### Get the full images fron the train dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "chemical-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()\n",
    "train_dataset = train_loader.dataset\n",
    "sp_images = train_dataset.imgs\n",
    "metadatas = train_dataset.metadatas\n",
    "f_names = [meta.f_name for meta in metadatas]\n",
    "cell_to_code_dict = sp_images[0]._categories_to_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-panel",
   "metadata": {},
   "source": [
    "### 1. Analyze sparse images by tiling them with patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supposed-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.misc_utils.dict_util import inspect_dict\n",
    "from tissue_purifier.model_utils.analyzer import SpatialAutocorrelation, Composition\n",
    "\n",
    "# ADD MORE MODELS, more features, etc\n",
    "\n",
    "N_patches_max = 100\n",
    "\n",
    "analyzers = [\n",
    "    Composition(return_fraction=True), \n",
    "    SpatialAutocorrelation(modality='moran', n_neighbours=6, neigh_correct=True)]\n",
    "\n",
    "feature_names= [\n",
    "    \"feature_composition\", \n",
    "    \"moran_I\"]\n",
    "\n",
    "for sp_img, f_name in zip(train_dataset.imgs, f_names):\n",
    "    sp_img.analyze_with_tiling(\n",
    "        cropper=dm.cropper_test,\n",
    "        patch_analyzers=analyzers,\n",
    "        feature_names=feature_names,\n",
    "        batch_size=64,\n",
    "        n_patches_max=N_patches_max,\n",
    "        overwrite=True)\n",
    "    sp_img.patch_properties_dict['classify_tissue_label'] = [f_name] * N_patches_max\n",
    "    \n",
    "# inspect_dict(sp_img.patch_properties_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-affairs",
   "metadata": {},
   "source": [
    "# 2. Concatenate the embeddings from all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "essential-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_composition <class 'torch.Tensor'> torch.Size([600, 9]) cpu\n",
      "moran_I <class 'torch.Tensor'> torch.Size([600, 9]) cpu\n",
      "patch_xywh <class 'torch.Tensor'> torch.Size([600, 4]) cpu\n",
      "classify_tissue_label <class 'list'> 600\n"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.misc_utils.dict_util import concatenate_list_of_dict\n",
    "\n",
    "list_of_dict = [sp_img.patch_properties_dict for sp_img in sp_images]\n",
    "all_features_dict = concatenate_list_of_dict(list_of_dict)\n",
    "inspect_dict(all_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-chart",
   "metadata": {},
   "source": [
    "### 3. Perform PCA, UMAP, Leiden on the learned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blind-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.misc_utils.misc import SmartPca, SmartUmap, SmartLeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "killing-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = ['feature_composition'] #features_teacher_bbone', 'features_composition']\n",
    "\n",
    "for key in feature_keys:\n",
    "    # print(\"working on -->\", key)\n",
    "    if key.endswith(\"composition\"):\n",
    "        smart_pca = SmartPca(preprocess_strategy='z_score')\n",
    "        smart_umap = SmartUmap(n_neighbors=25, preprocess_strategy='raw', n_components=2, min_dist=0.5, metric='cosine')\n",
    "        input_features = all_features_dict[key]\n",
    "        embeddings_pca = smart_pca.fit_transform(input_features, n_components=0.9)\n",
    "        embeddings_umap = smart_umap.fit_transform(input_features)\n",
    "        umap_graph = smart_umap.get_graph()\n",
    "    else:\n",
    "        smart_pca = SmartPca(preprocess_strategy='z_score')\n",
    "        smart_umap = SmartUmap(n_neighbors=25, preprocess_strategy='raw', n_components=2, min_dist=0.5, metric='euclidean')\n",
    "        input_features = all_features_dict[key]\n",
    "        embeddings_pca = smart_pca.fit_transform(input_features, n_components=0.9)\n",
    "        embeddings_umap = smart_umap.fit_transform(embeddings_pca)\n",
    "        umap_graph = smart_umap.get_graph()\n",
    "    \n",
    "    all_features_dict[\"pca_\"+key] = torch.from_numpy(embeddings_pca)\n",
    "    all_features_dict[\"umap_\"+key] = torch.from_numpy(embeddings_umap)\n",
    "    \n",
    "    smart_leiden = SmartLeiden(graph=umap_graph)\n",
    "    for resolution in [0.01, 0.1, 0.3, 0.5]:\n",
    "        cluster_labels = smart_leiden.cluster(resolution=resolution)\n",
    "        all_features_dict[\"leiden_res_\"+str(resolution)+\"_\"+key] = torch.nn.functional.one_hot(torch.from_numpy(cluster_labels).long())  # need to make it one-hot so that I can average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "divided-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect_dict(all_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-cleaner",
   "metadata": {},
   "source": [
    "Plot a lot of maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "duplicate-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.plot_utils.plot_embeddings import plot_all_maps\n",
    "\n",
    "maps = plot_all_maps(all_features_dict, legend=False)\n",
    "\n",
    "for tmp in maps:\n",
    "    exp[\"maps\"].log(neptune.types.File.as_image(tmp))\n",
    "    \n",
    "#maps[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-inventory",
   "metadata": {},
   "source": [
    "Add some quantities to regress and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "subjective-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect_dict(all_features_dict)\n",
    "\n",
    "all_features_dict['regress_moran'] = torch.max(all_features_dict['moran_I'], dim=-1)[0]\n",
    "all_features_dict['classify_condition'] = ['wt' if label.startswith('wt') else 'dis' for label in all_features_dict['classify_tissue_label']]\n",
    "\n",
    "#inspect_dict(all_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "neutral-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_features_dict, \"all_features_dist.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-scholar",
   "metadata": {},
   "source": [
    "# 3. Transfer the annotations to the sparse_images.patch_properties_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "black-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.misc_utils.dict_util import transfer_annotations_between_dict\n",
    "    \n",
    "anchor_key = 'patch_xywh'\n",
    "annotation_keys = list(all_features_dict.keys())\n",
    "annotation_keys.remove('patch_xywh')\n",
    "    \n",
    "for sp_img in sp_images:    \n",
    "    transfer_annotations_between_dict(\n",
    "        source_dict=all_features_dict,\n",
    "        dest_dict=sp_img.patch_properties_dict,\n",
    "        annotation_keys=annotation_keys,\n",
    "        anchor_key=anchor_key,\n",
    "    )\n",
    "\n",
    "#inspect_dict(sp_images[0].patch_properties_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-hardwood",
   "metadata": {},
   "source": [
    "### 2. From path property to image property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adaptive-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_composition', 'moran_I', 'pca_feature_composition', 'umap_feature_composition', 'leiden_res_0.01_feature_composition', 'leiden_res_0.1_feature_composition', 'leiden_res_0.3_feature_composition', 'leiden_res_0.5_feature_composition', 'regress_moran']\n",
      "The key feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key moran_I is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key pca_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key umap_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.01_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.1_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.3_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.5_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key regress_moran is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key moran_I is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key pca_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key umap_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.01_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.1_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.3_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.5_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key regress_moran is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key moran_I is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key pca_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key umap_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.01_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.1_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.3_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.5_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key regress_moran is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key moran_I is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key pca_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key umap_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.01_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.1_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.3_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.5_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key regress_moran is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key moran_I is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key pca_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key umap_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.01_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.1_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.3_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.5_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key regress_moran is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key moran_I is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key pca_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key umap_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.01_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.1_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.3_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key leiden_res_0.5_feature_composition is already present in image_properties_dict.                         This value will be overwritten\n",
      "The key regress_moran is already present in image_properties_dict.                         This value will be overwritten\n"
     ]
    }
   ],
   "source": [
    "annotation_keys = list(sp_images[0].patch_properties_dict.keys())\n",
    "annotation_keys.remove('classify_condition')\n",
    "annotation_keys.remove('classify_tissue_label')\n",
    "annotation_keys.remove('patch_xywh')\n",
    "print(annotation_keys)\n",
    "\n",
    "for sp_img in sp_images:\n",
    "    sp_img.path_property_to_image_property(\n",
    "        keys=annotation_keys,\n",
    "        overwrite=True,\n",
    "        verbose=False)\n",
    "\n",
    "#inspect_dict(image_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-forum",
   "metadata": {},
   "source": [
    "### 3. Visualize the Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pretty-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.plot_utils.plot_images import show_raw_all_channels, show_raw_one_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-bathroom",
   "metadata": {},
   "source": [
    "Plot the cell composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "living-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = list(cell_to_code_dict.keys())\n",
    "\n",
    "for sp_img, f_name in zip(sp_images, f_names):\n",
    "    fig = show_raw_one_channel(sp_img.image_properties_dict[\"feature_composition\"], n_col=3, in_range=(0.0, 1.0),\n",
    "                    titles=list(cell_to_code_dict.keys()), sup_title=\"Cell Composition of {0}\".format(f_name), cmap=\"magma\")\n",
    "    exp[\"masks/cell_composition\"].log(neptune.types.File.as_image(fig))\n",
    "#fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "engaging-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type, code in cell_to_code_dict.items():\n",
    "    # print(cell_type, code)\n",
    "    fig = show_raw_one_channel([sp_img.image_properties_dict[\"feature_composition\"][code] for sp_img in sp_images], n_col=3, \n",
    "                               in_range=(0.0, 1.0),\n",
    "                               titles=f_names, sup_title=\"Cell Composition of {0}\".format(cell_type), cmap=\"magma\")\n",
    "    exp[\"masks/cell_composition\"].log(neptune.types.File.as_image(fig))\n",
    "\n",
    "#fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-offset",
   "metadata": {},
   "source": [
    "Plot the moran score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "commercial-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_raw_one_channel([sp_img.image_properties_dict[\"regress_moran\"][0] for sp_img in sp_images], n_col=3, \n",
    "                            scale_each=False, in_range='image', \n",
    "                            titles=f_names, sup_title=\"Moran score\", cmap=\"magma\")\n",
    "exp[\"masks/moran\"].log(neptune.types.File.as_image(fig))\n",
    "#fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-lewis",
   "metadata": {},
   "source": [
    "Plot the Lieden cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "lucky-accessory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leiden_res_0.01_feature_composition\n",
      "leiden_res_0.1_feature_composition\n",
      "leiden_res_0.3_feature_composition\n",
      "leiden_res_0.5_feature_composition\n"
     ]
    }
   ],
   "source": [
    "image_keys = sp_images[0].image_properties_dict.keys()\n",
    "for key in image_keys:\n",
    "    if key.startswith(\"leiden\"):\n",
    "        print(key)\n",
    "        fig = show_raw_all_channels([sp_img.image_properties_dict[key] for sp_img in sp_images], n_col=3, titles=f_names, sup_title=key, cmap=plt.cm.tab10, show_colorbar=False)\n",
    "        exp[\"masks/leiden/all_chs\"].log(neptune.types.File.as_image(fig))\n",
    "#fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "macro-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_keys = sp_images[0].image_properties_dict.keys()\n",
    "for key in image_keys:\n",
    "    if key.startswith(\"leiden\"):\n",
    "        for sp_img, f_name in zip(sp_images, f_names):\n",
    "            n_clusters = sp_img.image_properties_dict[key].shape[-3]\n",
    "            titles = [\"leiden cluster: \"+str(n) for n in range(n_clusters)]\n",
    "            fig = show_raw_one_channel(sp_img.image_properties_dict[key], sup_title=\"{0} by {1}\".format(f_name,key),\n",
    "                                      titles=titles)\n",
    "            exp[\"masks/leiden/\"+key].log(neptune.types.File.as_image(fig))\n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-flower",
   "metadata": {},
   "source": [
    "Plot the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "amazing-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_feature_composition\n"
     ]
    }
   ],
   "source": [
    "for key in image_keys:\n",
    "    if key.startswith(\"pca\"):\n",
    "        print(key)\n",
    "        fig = show_raw_one_channel([sp_img.image_properties_dict[key][0] for sp_img in sp_images], n_col=3, titles=f_names, sup_title=\"PCA1 by \"+key, cmap=\"seismic\")\n",
    "        exp[\"masks/pca\"].log(neptune.types.File.as_image(fig))\n",
    "        fig = show_raw_one_channel([sp_img.image_properties_dict[key][1] for sp_img in sp_images], n_col=3, titles=f_names, sup_title=\"PCA2 by \"+key, cmap=\"seismic\")\n",
    "        exp[\"masks/pca\"].log(neptune.types.File.as_image(fig))\n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-mills",
   "metadata": {},
   "source": [
    "Plot the UMAP components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "starting-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap_feature_composition\n"
     ]
    }
   ],
   "source": [
    "for key in image_keys:\n",
    "    if key.startswith(\"umap\"):\n",
    "        print(key)\n",
    "        fig = show_raw_one_channel([sp_img.image_properties_dict[key][0] for sp_img in sp_images], n_col=3, titles=f_names, sup_title=\"UMAP1 by \"+key, cmap=\"seismic\")\n",
    "        exp[\"masks/umap\"].log(neptune.types.File.as_image(fig))\n",
    "        fig = show_raw_one_channel([sp_img.image_properties_dict[key][1] for sp_img in sp_images], n_col=3, titles=f_names, sup_title=\"UMAP2 by \"+key, cmap=\"seismic\")\n",
    "        exp[\"masks/umap\"].log(neptune.types.File.as_image(fig))\n",
    "        \n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-polish",
   "metadata": {},
   "source": [
    "### 4. Transfer annotation on spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect_dict(sp_images[0].image_properties_dict)\n",
    "\n",
    "keys_image = list(sp_images[0].image_properties_dict.keys())\n",
    "keys_image.remove(\"umap_feature_composition\")\n",
    "keys_image.remove(\"pca_feature_composition\")\n",
    "keys_image.remove(\"moran_I\")\n",
    "\n",
    "for sp_img in sp_images:\n",
    "    sp_img.image_property_to_spot_property(\n",
    "        keys=keys_image,\n",
    "        overwrite=True)\n",
    "    \n",
    "# inspect_dict(sp_images[0].spot_properties_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-aircraft",
   "metadata": {},
   "source": [
    "# Usage statistics of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "material-effects",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TODO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2494f9b4f745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TODO' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "original-disabled",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_counters' from 'tissue_purifier.plot_utils.plot_misc' (/mnt/disks/additional_persistent_disk/REPOS/ML_for_slideseq/src/tissue_purifier/plot_utils/plot_misc.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0381b36c8b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtissue_purifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_misc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_counters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtissue_purifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchannel_counter_in_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_counters' from 'tissue_purifier.plot_utils.plot_misc' (/mnt/disks/additional_persistent_disk/REPOS/ML_for_slideseq/src/tissue_purifier/plot_utils/plot_misc.py)"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.plot_utils.plot_misc import plot_counters\n",
    "from tissue_purifier.misc_utils.misc import channel_counter_in_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in image_keys:\n",
    "    if key.startswith(\"leiden\"):\n",
    "        print(key)\n",
    "        leiden_counters = [channel_counter_in_window(sp_img.image_properties_dict[key]) for sp_img in sp_images]\n",
    "        fig = plot_counters(leiden_counters, dataset_labels=f_names, title=\"normalized utilization of clusters by {0}\".format(key))\n",
    "        exp[\"usage\"].log(neptune.types.File.as_image(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = list(sp_images[0]._categories_to_codes.keys())\n",
    "\n",
    "cell_counters = [channel_counter_in_window(sp_img) for sp_img in sp_images]\n",
    "fig = plot_counters(cell_counters, dataset_labels=f_names, title=\"normalized utilization of cells\", x_labels=cell_types)\n",
    "exp[\"usage\"].log(neptune.types.File.as_image(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-conditioning",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "healthy-opinion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "twenty-israel",
   "metadata": {},
   "source": [
    "# Now you can do DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "typical-being",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-f091c5049fd2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-f091c5049fd2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    TO DO\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather all spot dict from the sparse images.... do DE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-spray",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
