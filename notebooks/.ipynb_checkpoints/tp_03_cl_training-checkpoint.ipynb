{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assumed-preparation",
   "metadata": {},
   "source": [
    "# Contrastive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-resort",
   "metadata": {},
   "source": [
    "### Add the src folder to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "isolated-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(root_path, \"src\")\n",
    "sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "serious-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-transition",
   "metadata": {},
   "source": [
    "### Read in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "respiratory-liberal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neptune_project': 'fedorgrab/slide-seq-contrastive',\n",
       " 'experiment_name': 'New Settings: 170',\n",
       " 'experiment_tags': ['CL', 'Final', 'New Settings'],\n",
       " 'simulation': {'MAX_EPOCHS': 2000,\n",
       "  'BATCH_SIZE': 128,\n",
       "  'CROP_SIZE': 224,\n",
       "  'INPUT_SIZE': 224,\n",
       "  'N_ELEMENT_MIN': 1000,\n",
       "  'N_CROPS_TEST': 1600,\n",
       "  'PIXEL_SIZE': 4,\n",
       "  'NUMBER_OF_CHANNELS': 9,\n",
       "  'RANDOM_SEED': 1},\n",
       " 'model_settings': {'BACKBONE_TYPE': 'resnet18',\n",
       "  'BACKBONE_NUM_FTRS': 128,\n",
       "  'PROJECTION_OUT_DIM': 128,\n",
       "  'INPUT_CHANNELS': 9},\n",
       " 'optimizer': {'LEARNING_RATE': 0.001,\n",
       "  'IS_SCHEDULED': True,\n",
       "  'SCHEDULER_STEP_SIZE': 3,\n",
       "  'SCHEDULER_GAMMA': 0.995}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open(\"./config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-junction",
   "metadata": {},
   "source": [
    "### Common import and set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "changed-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tissue_purifier as tp\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "torch.manual_seed(config['simulation']['RANDOM_SEED'])\n",
    "np.random.seed(config['simulation']['RANDOM_SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-amendment",
   "metadata": {},
   "source": [
    "### Read in all the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abroad-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = \"/home/jupyter/data/slide-seq/original_data/\"\n",
    "data_folder = \"../slide-seq-data\"\n",
    "\n",
    "df_wt1 = pd.read_csv(os.path.join(data_folder, \"wt_1.csv\"))\n",
    "df_wt2 = pd.read_csv(os.path.join(data_folder, \"wt_2.csv\"))\n",
    "df_wt3 = pd.read_csv(os.path.join(data_folder, \"wt_3.csv\"))\n",
    "df_dis1 = pd.read_csv(os.path.join(data_folder, \"sick_1.csv\"))\n",
    "df_dis2 = pd.read_csv(os.path.join(data_folder, \"sick_2.csv\"))\n",
    "df_dis3 = pd.read_csv(os.path.join(data_folder, \"sick_3.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-workshop",
   "metadata": {},
   "source": [
    "### Use all the tissues to create the trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dietary-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 31659\n",
      "The dense shape of the image is -> torch.Size([9, 1168, 1168])\n",
      "number of elements ---> 33059\n",
      "The dense shape of the image is -> torch.Size([9, 1170, 845])\n",
      "number of elements ---> 39206\n",
      "The dense shape of the image is -> torch.Size([9, 1169, 1170])\n",
      "number of elements ---> 27194\n",
      "The dense shape of the image is -> torch.Size([9, 1166, 1170])\n",
      "number of elements ---> 42776\n",
      "The dense shape of the image is -> torch.Size([9, 1170, 1170])\n",
      "number of elements ---> 33441\n",
      "The dense shape of the image is -> torch.Size([9, 1154, 1155])\n"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.data_utils.helpers import define_trainloader\n",
    "\n",
    "all_df = [df_wt1, df_wt2, df_wt3, df_dis1, df_dis2, df_dis3]\n",
    "labels_sparse_images = [0, 0, 0, 1, 1, 1]\n",
    "names_sparse_images = [\"wt1\", \"wt2\", \"wt3\", \"dis1\", \"dis2\", \"dis3\"]\n",
    "        \n",
    "sparse_images = [\n",
    "    tp.data_utils.SparseImage.from_panda(\n",
    "        df, x=\"x\", y=\"y\", category=\"cell_type\", pixel_size=config[\"simulation\"][\"PIXEL_SIZE\"], padding=10\n",
    "    )\n",
    "    for df in all_df\n",
    "]\n",
    "\n",
    "trainloader = define_trainloader(sparse_images,\n",
    "                                 labels_sparse_images,\n",
    "                                 names_sparse_images,\n",
    "                                 config,\n",
    "                                 simclr_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-imperial",
   "metadata": {},
   "source": [
    "### Create the model, optimizer and loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "complicated-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly\n",
    "from tissue_purifier.model_utils.encoder import Encoder\n",
    "\n",
    "model = tp.model_utils.helpers.define_model(\n",
    "    backbone_type=config[\"model_settings\"][\"BACKBONE_TYPE\"],\n",
    "    number_of_channels=config[\"model_settings\"][\"INPUT_CHANNELS\"],\n",
    "    num_of_filters=config[\"model_settings\"][\"BACKBONE_NUM_FTRS\"],\n",
    "    projection_out_dim=config[\"model_settings\"][\"PROJECTION_OUT_DIM\"],\n",
    ")\n",
    "\n",
    "optimizer, scheduler = tp.model_utils.helpers.define_optimizer_and_scheduler(\n",
    "    model=model,\n",
    "    num_epochs=config[\"simulation\"][\"MAX_EPOCHS\"],\n",
    "    learning_rate=config[\"optimizer\"][\"LEARNING_RATE\"], \n",
    "    scheduler_step_size=config[\"optimizer\"][\"SCHEDULER_STEP_SIZE\"],\n",
    "    scheduler_gamma=config[\"optimizer\"][\"SCHEDULER_GAMMA\"]\n",
    ")\n",
    "\n",
    "criterion = tp.loss_utils.helpers.define_contrastive_loss()\n",
    "\n",
    "encoder = Encoder(\n",
    "    model, criterion, optimizer, trainloader, scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "norman-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-washington",
   "metadata": {},
   "source": [
    "## Train the model on GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "model_folder = \"../trained_model\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "encoder.train_embedding(\n",
    "    gpus=gpus, \n",
    "    progress_bar_refresh_rate=0, \n",
    "    max_epochs=MAX_EPOCHS, \n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(model_folder, \"simclr_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-agriculture",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "activated-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute efficiency: 0.35:   8%|â–Š         | 1/13 [00:22<04:27, 22.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bb79c27b90b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                config)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m embeddings, labels, fnames = encoder.embed_by_backbone(testloader, \n\u001b[0m\u001b[1;32m      9\u001b[0m                                                        \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                        to_numpy=False)\n",
      "\u001b[0;32m~/REPOS/ML_for_slideseq/src/tissue_purifier/model_utils/encoder.py\u001b[0m in \u001b[0;36membed_by_backbone\u001b[0;34m(self, dataloader, device, to_numpy)\u001b[0m\n\u001b[1;32m     32\u001b[0m                           \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                           to_numpy: bool = True):\n\u001b[0;32m---> 34\u001b[0;31m         return self.__embed(dataloader=dataloader,\n\u001b[0m\u001b[1;32m     35\u001b[0m                             \u001b[0membedding_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__embed_image_by_backbone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/REPOS/ML_for_slideseq/src/tissue_purifier/model_utils/encoder.py\u001b[0m in \u001b[0;36m__embed\u001b[0;34m(self, dataloader, embedding_callback, device, to_numpy)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/REPOS/ML_for_slideseq/src/tissue_purifier/data_utils/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_fname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/REPOS/ML_for_slideseq/src/tissue_purifier/data_utils/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             return (\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/REPOS/ML_for_slideseq/src/tissue_purifier/data_utils/transforms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             return (\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tissue_purifier.data_utils.helpers import define_testloader\n",
    "\n",
    "testloader = define_testloader(sparse_images,\n",
    "                               labels_sparse_images,\n",
    "                               names_sparse_images,\n",
    "                               config)\n",
    "\n",
    "embeddings, labels, fnames = encoder.embed_by_backbone(testloader, \n",
    "                                                       device=sparse_images[0].device, \n",
    "                                                       to_numpy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-portfolio",
   "metadata": {},
   "source": [
    "### Check the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "anticipated-rendering",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3854a3178b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embeddings.shape -->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"embeddings.shape -->\", embeddings.shape)\n",
    "tp.plot_utils.plot_knn_examples(embeddings, test_dataloader, figsize=(5, 8), n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "parliamentary-devil",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9ca9ba450122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mumap_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_umap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "umap_embeddings = tp.evaluation_utils.get_umap(embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_utils.umap_binary_label(umap_embedded=umap_embeddings, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "morans = tp.evaluation_utils.get_morans(test_dataloader, all_df=all_df, pixel_size=PIXEL_SIZE, crop_size=CROP_SIZE)\n",
    "tp.plot_utils.umap(umap_embedded=umap_embeddings, colors=morans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_emb = tp.evaluation_utils.get_pca(embeddings)\n",
    "tp.plot_utils.pca(pca_emb, morans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_emb = tp.evaluation_utils.get_tsne(embeddings)\n",
    "tp.plot_utils.tsne(tsne_emb, morans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.evaluation_utils.create_projector(\n",
    "    test_dataloader, embeddings, {\"labels\": labels, \"morans\": morans}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
