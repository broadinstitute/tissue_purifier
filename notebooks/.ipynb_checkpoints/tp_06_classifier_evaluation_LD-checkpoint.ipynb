{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sublime-latitude",
   "metadata": {},
   "source": [
    "# Classifier Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-basement",
   "metadata": {},
   "source": [
    "### Make sure the src file is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "invalid-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(root_path, \"src\")\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-bryan",
   "metadata": {},
   "source": [
    "### Read in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "female-eligibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neptune_project': 'fedorgrab/slide-seq-contrastive',\n",
       " 'experiment_name': 'New Settings: 170',\n",
       " 'experiment_tags': ['CL', 'Final', 'New Settings'],\n",
       " 'simulation': {'MAX_EPOCHS': 2000,\n",
       "  'BATCH_SIZE': 128,\n",
       "  'CROP_SIZE': 224,\n",
       "  'INPUT_SIZE': 224,\n",
       "  'N_ELEMENT_MIN': 800,\n",
       "  'N_CROPS_TEST': 1600,\n",
       "  'PIXEL_SIZE': 4,\n",
       "  'NUMBER_OF_CHANNELS': 9,\n",
       "  'RANDOM_SEED': 1},\n",
       " 'model_settings': {'BACKBONE_NUM_FTRS': 128, 'PROJECTION_OUT_DIM': 128},\n",
       " 'optimizer': {'LEARNING_RATE': 0.001,\n",
       "  'IS_SCHEDULED': True,\n",
       "  'SCHEDULER_STEP_SIZE': 3,\n",
       "  'SCHEDULER_GAMMA': 0.995}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open(\"./config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-cisco",
   "metadata": {},
   "source": [
    "### Common import and set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "superb-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tissue_purifier as tp\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "torch.manual_seed(config['simulation']['RANDOM_SEED'])\n",
    "np.random.seed(config['simulation']['RANDOM_SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-broadway",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "young-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = = \"/home/jupyter/data/slide-seq/original_data/\"\n",
    "data_folder = \"../slide-seq-data\"\n",
    "\n",
    "df_wt1 = pd.read_csv(os.path.join(data_folder, \"wt_1.csv\"))\n",
    "df_wt2 = pd.read_csv(os.path.join(data_folder, \"wt_2.csv\"))\n",
    "df_wt3 = pd.read_csv(os.path.join(data_folder, \"wt_3.csv\"))\n",
    "df_dis1 = pd.read_csv(os.path.join(data_folder, \"sick_1.csv\"))\n",
    "df_dis2 = pd.read_csv(os.path.join(data_folder, \"sick_2.csv\"))\n",
    "df_dis3 = pd.read_csv(os.path.join(data_folder, \"sick_3.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-operations",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "\n",
    "\n",
    "def get_classifier_and_dataloader(dfs, labels, cl_model_path, classifier_path):\n",
    "    print(\"Test Data:\")\n",
    "    test_sparse_images = tp.data_utils.SparseImage.from_pandas(\n",
    "        dfs, x=\"x\", y=\"y\", category=\"cell_type\", pixel_size=PIXEL_SIZE, padding=10\n",
    "    )\n",
    "    test_dataloader = tp.data_utils.helpers.define_dataloader_test(\n",
    "        sparse_images=test_sparse_images,\n",
    "        labels_sparse_images=labels,\n",
    "        input_size=INPUT_SIZE,\n",
    "        crop_size=CROP_SIZE,\n",
    "        n_crops_test=N_CROPS_TEST,\n",
    "        n_element_min=N_ELEMENT_MIN,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    model = tp.model_utils.helpers.define_model(\n",
    "        number_of_channels=INPUT_CHANNELS,\n",
    "        num_of_filters=NUM_FTRS,\n",
    "        projection_out_dim=PROJECTION_OUT_DIM\n",
    "    )\n",
    "    ckpt = torch.load(cl_model_path)\n",
    "    model.backbone.load_state_dict(ckpt[\"resnet18_parameters\"])\n",
    "\n",
    "    classifier = tp.model_utils.SimCLRBasedClassifier(\n",
    "        model=model, embedding_out_dim=NUM_FTRS, out_dim=2, max_epochs=MAX_EPOCHS\n",
    "    )\n",
    "    classifier.fc.load_state_dict(torch.load(classifier_path))\n",
    "    classifier = classifier.to(\"cuda\")\n",
    "    return classifier, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale \n",
    "from tissue_purifier.data_utils.transforms import RandomGaussianBlur\n",
    "\n",
    "def get_dense_image(df, pixel_size):\n",
    "    t = RandomGaussianBlur(sigma=(1.0, 1.0))(\n",
    "        tp.data_utils.SparseImage.from_panda(\n",
    "            df, x=\"x\", y=\"y\", category=\"cell_type\", pixel_size=pixel_size, padding=10\n",
    "        ).to_dense()\n",
    "    )\n",
    "    \n",
    "    a = np.zeros(t.shape)\n",
    "    for i in range(9):\n",
    "        a[i] = minmax_scale(t[i].cpu())\n",
    "        \n",
    "    return a.transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.simple_cache import cache\n",
    "\n",
    "offset = 0\n",
    "CROP_SIZE = 224\n",
    "\n",
    "def get_sickness_mask(image, image_label, threshold=0.5, return_probas=False):\n",
    "    intensity_mask = np.zeros(image.shape[:-1])\n",
    "    count_mask = np.zeros(image.shape[:-1])\n",
    "    xys = cache[\"test\"]\n",
    "    for i, (proba, real_answer) in enumerate(zip(y_probas, y_true)):\n",
    "        if real_answer == image_label:\n",
    "            crop_i, crop_j = xys[indicies[i]]\n",
    "            intensity_mask[\n",
    "                crop_i + offset: crop_i + CROP_SIZE - offset, crop_j + offset: crop_j + CROP_SIZE - offset\n",
    "            ] += proba\n",
    "            count_mask[crop_i + offset: crop_i + CROP_SIZE - offset, crop_j + offset: crop_j + CROP_SIZE - offset] += 1\n",
    "    \n",
    "    count_mask = np.where(count_mask > 10, count_mask, 0)    \n",
    "    \n",
    "    proba_mask = intensity_mask / count_mask\n",
    "    proba_mask = np.where(proba_mask == np.inf, 0, proba_mask)\n",
    "    proba_mask = np.where(proba_mask == np.nan, 0, proba_mask)\n",
    "    \n",
    "    if return_probas:\n",
    "        return proba_mask\n",
    "\n",
    "    return np.where(proba_mask > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-singapore",
   "metadata": {},
   "source": [
    "## Classifier 1 (Sample 1) masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_wt2 = get_dense_image(df_wt2, PIXEL_SIZE)\n",
    "img_dis2 = get_dense_image(df_dis2, PIXEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, test_dataloader = get_classifier_and_dataloader(\n",
    "    dfs=[df_wt1, df_dis1],\n",
    "    labels=[0, 1],\n",
    "    cl_model_path=\"model.pth\",\n",
    "    classifier_path=\"classifier_1_fc.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_probas = []\n",
    "indicies = []\n",
    "\n",
    "for batch, labels, fnames in test_dataloader:\n",
    "    y_true.append(labels.cpu())\n",
    "    y_probas.append(torch.softmax(classifier(batch), dim=-1).cpu()[:, 1].detach())\n",
    "    indicies.append(fnames)\n",
    "    \n",
    "    \n",
    "y_probas = np.concatenate(y_probas)\n",
    "y_true = np.concatenate(y_true)\n",
    "indicies = np.concatenate(indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = get_sickness_mask(img_wt2, 0, threshold=0.57)#,return_probas=True)\n",
    "mask_2 = get_sickness_mask(img_dis2, 1, threshold=0.49)#, return_probas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6,3))\n",
    "\n",
    "ax1.imshow(img_wt2[:, :, :3])\n",
    "ax1.imshow(mask_1, alpha=0.5, cmap=\"gray\")\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title(\"WT 2\");\n",
    "\n",
    "ax2.imshow(img_dis2[:,:,:3])\n",
    "ax2.imshow(mask_2, alpha=0.45, cmap=\"gray\")\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title(\"DIS 2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(row, mask, x_min, y_min, pixel_size):\n",
    "    i = int((row.y - y_min) / pixel_size)\n",
    "    j = int((row.x - x_min) / pixel_size)\n",
    "    return mask[j, i]\n",
    "\n",
    "def get_mask_probas_for_df(df, mask, pixel_size):\n",
    "    x_min, y_min = df.x.min(), df.y.min()\n",
    "    return df.apply(lambda row: get_probability(row, mask, x_min, y_min, pixel_size=pixel_size), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wt2[\"probas\"] = get_mask_probas_for_df(df_wt2, mask_1, pixel_size=4)\n",
    "df_dis2[\"probas\"] = get_mask_probas_for_df(df_dis2, mask_2, pixel_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(8, 4))\n",
    "tp.plot_utils.show_raw_data(df_wt2, title=\"Sample WT 2\", ax=ax1, point_size=0.5, color_map=plt.cm.Paired)\n",
    "tp.plot_utils.show_raw_data(df_dis2, title=\"Sample DIS 2\", ax=ax2, point_size=0.5, color_map=plt.cm.Paired)\n",
    "ax1.scatter(df_wt2.x, df_wt2.y, c=df_wt2.probas, alpha=0.07, s=1.5, cmap=\"gray\")\n",
    "ax2.scatter(df_dis2.x, df_dis2.y, c=df_dis2.probas, alpha=0.07, s=1.5, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-algorithm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
