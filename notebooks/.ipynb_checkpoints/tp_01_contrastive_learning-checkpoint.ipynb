{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assumed-preparation",
   "metadata": {},
   "source": [
    "# Contrastive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-resort",
   "metadata": {},
   "source": [
    "### Add the src folder to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "isolated-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(root_path, \"src\")\n",
    "sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serious-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-transition",
   "metadata": {},
   "source": [
    "### Read in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respiratory-liberal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neptune_project': 'fedorgrab/slide-seq-contrastive',\n",
       " 'experiment_name': 'New Settings: 170',\n",
       " 'experiment_tags': ['CL', 'Final', 'New Settings'],\n",
       " 'simulation': {'MAX_EPOCHS': 2000,\n",
       "  'BATCH_SIZE': 128,\n",
       "  'CROP_SIZE': 224,\n",
       "  'INPUT_SIZE': 224,\n",
       "  'N_ELEMENT_MIN': 1000,\n",
       "  'N_CROPS_TEST': 1600,\n",
       "  'PIXEL_SIZE': 4,\n",
       "  'NUMBER_OF_CHANNELS': 9,\n",
       "  'RANDOM_SEED': 1},\n",
       " 'model_settings': {'BACKBONE_TYPE': 'resnet18',\n",
       "  'BACKBONE_NUM_FTRS': 128,\n",
       "  'PROJECTION_OUT_DIM': 128,\n",
       "  'INPUT_CHANNELS': 9},\n",
       " 'optimizer': {'LEARNING_RATE': 0.001,\n",
       "  'IS_SCHEDULED': True,\n",
       "  'SCHEDULER_STEP_SIZE': 3,\n",
       "  'SCHEDULER_GAMMA': 0.995}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open(\"./config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-junction",
   "metadata": {},
   "source": [
    "### Common import and set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "changed-membrane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ldalessi/anaconda3/envs/pyro/lib/python3.8/site-packages/lightly/api/version_checking.py:57: Warning: You are using lightly version 1.1.12. There is a newer version of the package available. For compatability reasons, please upgrade your current version: pip install lightly==1.1.14\n",
      "  warnings.warn(Warning(warning))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tissue_purifier as tp\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "torch.manual_seed(config['simulation']['RANDOM_SEED'])\n",
    "np.random.seed(config['simulation']['RANDOM_SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-amendment",
   "metadata": {},
   "source": [
    "### Read in all the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abroad-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = \"/home/jupyter/data/slide-seq/original_data/\"\n",
    "data_folder = \"../slide-seq-data\"\n",
    "\n",
    "df_wt1 = pd.read_csv(os.path.join(data_folder, \"wt_1.csv\"))\n",
    "df_wt2 = pd.read_csv(os.path.join(data_folder, \"wt_2.csv\"))\n",
    "df_wt3 = pd.read_csv(os.path.join(data_folder, \"wt_3.csv\"))\n",
    "df_dis1 = pd.read_csv(os.path.join(data_folder, \"sick_1.csv\"))\n",
    "df_dis2 = pd.read_csv(os.path.join(data_folder, \"sick_2.csv\"))\n",
    "df_dis3 = pd.read_csv(os.path.join(data_folder, \"sick_3.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-workshop",
   "metadata": {},
   "source": [
    "### Use all the tissues to create the trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dietary-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 31659\n",
      "The dense shape of the image is -> torch.Size([9, 1168, 1168])\n",
      "number of elements ---> 33059\n",
      "The dense shape of the image is -> torch.Size([9, 1170, 845])\n",
      "number of elements ---> 39206\n",
      "The dense shape of the image is -> torch.Size([9, 1169, 1170])\n",
      "number of elements ---> 27194\n",
      "The dense shape of the image is -> torch.Size([9, 1166, 1170])\n",
      "number of elements ---> 42776\n",
      "The dense shape of the image is -> torch.Size([9, 1170, 1170])\n",
      "number of elements ---> 33441\n",
      "The dense shape of the image is -> torch.Size([9, 1154, 1155])\n"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.data_utils.helpers import define_trainloader\n",
    "\n",
    "all_df = [df_wt1, df_wt2, df_wt3, df_dis1, df_dis2, df_dis3]\n",
    "labels_sparse_images = [0, 0, 0, 1, 1, 1]\n",
    "names_sparse_images = [\"wt1\", \"wt2\", \"wt3\", \"dis1\", \"dis2\", \"dis3\"]\n",
    "        \n",
    "sparse_images = [\n",
    "    tp.data_utils.SparseImage.from_panda(\n",
    "        df, x=\"x\", y=\"y\", category=\"cell_type\", pixel_size=config[\"simulation\"][\"PIXEL_SIZE\"], padding=10\n",
    "    )\n",
    "    for df in all_df\n",
    "]\n",
    "\n",
    "trainloader = define_trainloader(sparse_images,\n",
    "                                 labels_sparse_images,\n",
    "                                 names_sparse_images,\n",
    "                                 config,\n",
    "                                 simclr_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-imperial",
   "metadata": {},
   "source": [
    "### Create the model, optimizer and loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complicated-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly\n",
    "from tissue_purifier.model_utils.encoder import Encoder\n",
    "\n",
    "model = tp.model_utils.helpers.define_model(\n",
    "    backbone_type=config[\"model_settings\"][\"BACKBONE_TYPE\"],\n",
    "    number_of_channels=config[\"model_settings\"][\"INPUT_CHANNELS\"],\n",
    "    num_of_filters=config[\"model_settings\"][\"BACKBONE_NUM_FTRS\"],\n",
    "    projection_out_dim=config[\"model_settings\"][\"PROJECTION_OUT_DIM\"],\n",
    ")\n",
    "\n",
    "optimizer, scheduler = tp.model_utils.helpers.define_optimizer_and_scheduler(\n",
    "    model=model,\n",
    "    num_epochs=config[\"simulation\"][\"MAX_EPOCHS\"],\n",
    "    learning_rate=config[\"optimizer\"][\"LEARNING_RATE\"], \n",
    "    scheduler_step_size=config[\"optimizer\"][\"SCHEDULER_STEP_SIZE\"],\n",
    "    scheduler_gamma=config[\"optimizer\"][\"SCHEDULER_GAMMA\"]\n",
    ")\n",
    "\n",
    "criterion = tp.loss_utils.helpers.define_contrastive_loss()\n",
    "\n",
    "encoder = Encoder(\n",
    "    model, criterion, optimizer, trainloader, scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "norman-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-washington",
   "metadata": {},
   "source": [
    "## Train the model on GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "model_folder = \"../trained_model\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "encoder.train_embedding(\n",
    "    gpus=gpus, \n",
    "    progress_bar_refresh_rate=0, \n",
    "    max_epochs=config[\"simulation\"][\"MAX_EPOCHS\"], \n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(model_folder, \"simclr_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-agriculture",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.data_utils.helpers import define_testloader\n",
    "\n",
    "testloader = define_testloader(sparse_images,\n",
    "                               labels_sparse_images,\n",
    "                               names_sparse_images,\n",
    "                               config)\n",
    "\n",
    "embeddings, labels, fnames = encoder.embed_by_backbone(testloader, \n",
    "                                                       device=sparse_images[0].device, \n",
    "                                                       to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "excellent-portfolio",
   "metadata": {},
   "source": [
    "### Check the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"embeddings.shape -->\", embeddings.shape)\n",
    "tp.plot_utils.plot_knn_examples(embeddings, test_dataloader, figsize=(5, 8), n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = tp.evaluation_utils.get_umap(embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_utils.umap_binary_label(umap_embedded=umap_embeddings, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "morans = tp.evaluation_utils.get_morans(test_dataloader, all_df=all_df, pixel_size=PIXEL_SIZE, crop_size=CROP_SIZE)\n",
    "tp.plot_utils.umap(umap_embedded=umap_embeddings, colors=morans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_emb = tp.evaluation_utils.get_pca(embeddings)\n",
    "tp.plot_utils.pca(pca_emb, morans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_emb = tp.evaluation_utils.get_tsne(embeddings)\n",
    "tp.plot_utils.tsne(tsne_emb, morans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.evaluation_utils.create_projector(\n",
    "    test_dataloader, embeddings, {\"labels\": labels, \"morans\": morans}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-munich",
   "metadata": {},
   "source": [
    "# Create a dataset to train a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tot, labels_tot, fnames_tot = [], [], []\n",
    "for epoch in range(3):\n",
    "    embeddings, labels, fnames = encoder.embed_by_backbone(trainloader, \n",
    "                                                           device=sparse_images[0].device, \n",
    "                                                           to_numpy=False)\n",
    "    embeddings_tot.append(embeddings)\n",
    "    labels_tot.append(labels)\n",
    "    fnames_tot += [*fnames]\n",
    "\n",
    "print(\"embeddings_tot.shape\", embeddings_tot.shape)\n",
    "torch.save([embeddings_tot, labels_tot, fnames_tot], os.path.join(model_folder, \"data_for_classifier.pt\"))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
