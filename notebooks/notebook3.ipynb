{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "split-cleaner",
   "metadata": {},
   "source": [
    "# Evaluate features\n",
    "\n",
    "This notebook demonstrate how to evaluate the features stored in the anndata.obsm.\n",
    "The task we are interested in is to predict the gene expression based on the cell_type label and the covariates. \n",
    "\n",
    "We evaluate different metric to show that the semantic features obtained from the self supervised learning (ssl) frameworks are biological relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1201329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REMOVE when notebook is stable\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-logic",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "living-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import seaborn\n",
    "import tarfile\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from anndata import read_h5ad\n",
    "\n",
    "# tissue_purifier import\n",
    "import tissue_purifier as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e0252",
   "metadata": {},
   "source": [
    "### Download an  anndata object with extra features stored in .obsm.\n",
    "\n",
    "Altenatively you can use the anndata file generated by running notebook2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unique-nashville",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './annotated_anndata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ee7e64817bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Make a list of all the h5ad files in the annotated_anndata_dest_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfname_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_anndata_dest_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.h5ad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfname_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './annotated_anndata'"
     ]
    }
   ],
   "source": [
    "import tissue_purifier.io\n",
    "\n",
    "bucket_name = \"ld-data-bucket\"\n",
    "annotated_anndata_source_path = \"tissue-purifier/annotated_slideseq_testis_anndata_h5ad.tar.gz\"\n",
    "annotated_anndata_dest_path = \"./annotated_slideseq_testis_anndata_h5ad.tar.gz\"\n",
    "annotated_anndata_dest_folder = \"./annotated_anndata\"\n",
    "\n",
    "#tp.io.download_from_bucket(bucket_name, annotated_anndata_source_path, annotated_anndata_dest_path)   \n",
    "#with tarfile.open(annotated_anndata_dest_path, \"r:gz\") as fp:\n",
    "#    fp.extractall(path=annotated_anndata_dest_folder)\n",
    "    \n",
    "# Make a list of all the h5ad files in the annotated_anndata_dest_folder\n",
    "fname_list = []\n",
    "for f in os.listdir(annotated_anndata_dest_folder):\n",
    "    if f.endswith('.h5ad'):\n",
    "        fname_list.append(f)\n",
    "print(fname_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db1d68",
   "metadata": {},
   "source": [
    "### Decide how to filter the anndata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2886b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cells parameters\n",
    "fc_bc_min_umi = 200\n",
    "fc_bc_max_umi = 3000\n",
    "fc_bc_min_n_genes_by_counts = 10\n",
    "fc_bc_max_n_genes_by_counts = 2500\n",
    "fc_bc_max_pct_counts_mt = 5\n",
    "\n",
    "# filter genes parameters\n",
    "fg_bc_min_cells_by_counts = 100\n",
    "\n",
    "# filter rare cell types parameters\n",
    "fctype_bc_min_cells_absolute = 100\n",
    "fctype_bc_min_cells_frequency = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff84026",
   "metadata": {},
   "source": [
    "### Open the first anndata and compute some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ad_file = fname_list[0]\n",
    "adata = anndata.read_h5ad(filename=h5ad_file)\n",
    "\n",
    "# mitocondria metrics\n",
    "adata.var['mt'] = adata.var_names.str.startswith('mt-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "# counts cells frequency\n",
    "tmp = adata.obs[cell_type_key].values.describe()\n",
    "mask1 = (tmp[\"counts\"] > fctype_dt_min_cells_absolute)\n",
    "mask2 = (tmp[\"freqs\"] > fctype_dt_min_cells_frequency)\n",
    "mask = mask1 * mask2\n",
    "cell_type_keep = set(tmp[mask].index.values)\n",
    "adata.obs[\"keep_ctype\"] = adata.obs[\"cell_type\"].apply(lambda x: x in cell_type_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f13f2",
   "metadata": {},
   "source": [
    "### Filter anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs[\"total_counts\"] > fc_dt_min_umi, :] \n",
    "adata = adata[adata.obs[\"total_counts\"] < fc_dt_max_umi, :] \n",
    "adata = adata[adata.obs[\"n_genes_by_counts\"] > fc_dt_min_n_genes_by_counts, :] \n",
    "adata = adata[adata.obs[\"n_genes_by_counts\"] < fc_dt_max_n_genes_by_counts, :] \n",
    "adata = adata[adata.obs[\"pct_counts_mt\"] < fc_dt_max_pct_counts_mt, :]\n",
    "adata = adata[adata.obs[\"keep_ctype\"] == True, :]\n",
    "adata = adata[:, adata.var[\"n_cells_by_counts\"] > fg_dt_min_cells_by_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49bfbf",
   "metadata": {},
   "source": [
    "### Make a gene dataset from the anndata and split it into train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90303512",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_keys = \"ncv_10\"\n",
    "\n",
    "gene_dataset = make_gene_dataset_from_anndata(\n",
    "        anndata=adata,\n",
    "        cell_type_key='cell_type',\n",
    "        covariate_key=covariate_key,\n",
    "        preprocess_strategy='raw',\n",
    "        apply_pca=False)\n",
    "    \n",
    "train_dataset, test_dataset, val_dataset = next(iter(train_test_val_split(gene_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890178dd",
   "metadata": {},
   "source": [
    "### train the gene regression model and test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = GeneRegression()\n",
    "gr.configure_optimizer(optimizer_type='adam', lr=5E-3)\n",
    "\n",
    "result = gr.train_and_test(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    test_num_samples=10,\n",
    "    train_steps=50,\n",
    "    train_print_frequency=5,\n",
    "    use_covariates=True,\n",
    "    l1_regularization_strength=0.1,\n",
    "    l2_regularization_strength=None,\n",
    "    eps_range=(1.0E-5, 1.0E-2),\n",
    "    subsample_size_cells=None,\n",
    "    subsample_size_genes=None,\n",
    "    from_scratch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5cae67",
   "metadata": {},
   "source": [
    "### visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11553783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
