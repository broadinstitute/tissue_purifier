{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "split-cleaner",
   "metadata": {},
   "source": [
    "# Self Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b862df",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a self supervised model on a collection of anndata objects and produce a \"complete\" checkpoint file. \\\n",
    "Here we are going to train the model for a short time just for demonstration. \\\n",
    "To reproduce the results in the paper run the scripts with provided config.yaml file. \\\n",
    "See documentation for details. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0a5a9",
   "metadata": {},
   "source": [
    "## Common imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182d535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove this once the notebook is stable\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664ad507",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 13 required positional arguments: 'backbone_type', 'image_in_ch', 'head_hidden_chs', 'head_out_ch', 'lambda_off_diagonal', 'optimizer_type', 'warm_up_epochs', 'warm_down_epochs', 'max_epochs', 'min_learning_rate', 'max_learning_rate', 'min_weight_decay', and 'max_weight_decay'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eb9bd2d4bf27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtissue_purifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBarlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBarlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 13 required positional arguments: 'backbone_type', 'image_in_ch', 'head_hidden_chs', 'head_out_ch', 'lambda_off_diagonal', 'optimizer_type', 'warm_up_epochs', 'warm_down_epochs', 'max_epochs', 'min_learning_rate', 'max_learning_rate', 'min_weight_decay', and 'max_weight_decay'"
     ]
    }
   ],
   "source": [
    "import tissue_purifier as tp\n",
    "\n",
    "from tissue_purifier.models import Barlow\n",
    "a = tp.models.Barlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa6fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tissue_purifier.models in tissue_purifier:\n",
      "\n",
      "NAME\n",
      "    tissue_purifier.models\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _optim_scheduler\n",
      "    classifier_regressor (package)\n",
      "    logger\n",
      "    patch_analyzer (package)\n",
      "    ssl_models (package)\n",
      "\n",
      "CLASSES\n",
      "    pytorch_lightning.loggers.neptune.NeptuneLogger(pytorch_lightning.loggers.base.LightningLoggerBase)\n",
      "        tissue_purifier.models.logger.NeptuneLoggerCkpt\n",
      "    \n",
      "    class NeptuneLoggerCkpt(pytorch_lightning.loggers.neptune.NeptuneLogger)\n",
      "     |  NeptuneLoggerCkpt(**kargs)\n",
      "     |  \n",
      "     |  Thin wrapper around the Neptune Logger with the after_save_checkpoint specified\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NeptuneLoggerCkpt\n",
      "     |      pytorch_lightning.loggers.neptune.NeptuneLogger\n",
      "     |      pytorch_lightning.loggers.base.LightningLoggerBase\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, **kargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  after_save_checkpoint(self, checkpoint_callback: 'ReferenceType[ModelCheckpoint]') -> None\n",
      "     |      Log checkpointed model.\n",
      "     |      Called after model checkpoint callback saves a new checkpoint.\n",
      "     |      Must work even when multiple ModelCheckPoint callbacks are present\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          checkpoint_callback: the model checkpoint callback instance\n",
      "     |  \n",
      "     |  delete_file_in_neptune(self, checkpoints_namespace, file_just_added)\n",
      "     |      Compare file already uploaded in neptune with the one recently added.\n",
      "     |      If some diff file have the same beginning as a file recently added I remove the old files.\n",
      "     |  \n",
      "     |  log_long_text(self, text, log_name)\n",
      "     |  \n",
      "     |  log_model_summary(self, model, log_name: str = 'training/model/summary', max_depth=-1)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  mtime_cromwell_checkpointing = -100.0\n",
      "     |  \n",
      "     |  path_to_cromwell_checkpointing = '/cromwell_root/my_checkpoint.ckpt'\n",
      "     |  \n",
      "     |  verbose = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pytorch_lightning.loggers.neptune.NeptuneLogger:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  append_tags(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  finalize(self, status: str) -> None\n",
      "     |      Do any processing that is necessary to finalize an experiment.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          status: Status that the experiment finished with (e.g. success, failed, aborted)\n",
      "     |  \n",
      "     |  log_artifact(self, artifact: str, destination: Union[str, NoneType] = None) -> None\n",
      "     |  \n",
      "     |  log_hyperparams(self, params: Union[Dict[str, Any], argparse.Namespace]) -> None\n",
      "     |      Log hyper-parameters to the run.\n",
      "     |      \n",
      "     |      Hyperparams will be logged under the \"<prefix>/hyperparams\" namespace.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |      \n",
      "     |          You can also log parameters by directly using the logger instance:\n",
      "     |          ``neptune_logger.experiment[\"model/hyper-parameters\"] = params_dict``.\n",
      "     |      \n",
      "     |          In this way you can keep hierarchical structure of the parameters.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          params: `dict`.\n",
      "     |              Python dictionary structure with parameters.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          from pytorch_lightning.loggers import NeptuneLogger\n",
      "     |      \n",
      "     |          PARAMS = {\n",
      "     |              \"batch_size\": 64,\n",
      "     |              \"lr\": 0.07,\n",
      "     |              \"decay_factor\": 0.97\n",
      "     |          }\n",
      "     |      \n",
      "     |          neptune_logger = NeptuneLogger(\n",
      "     |              api_key=\"ANONYMOUS\",\n",
      "     |              project=\"common/pytorch-lightning-integration\"\n",
      "     |          )\n",
      "     |      \n",
      "     |          neptune_logger.log_hyperparams(PARAMS)\n",
      "     |  \n",
      "     |  log_image(self, log_name: str, image: Union[str, Any], step: Union[int, NoneType] = None) -> None\n",
      "     |      Log image.\n",
      "     |      \n",
      "     |      Arguments are directly passed to the logger.\n",
      "     |  \n",
      "     |  log_metric(self, metric_name: str, metric_value: Union[torch.Tensor, float, str], step: Union[int, NoneType] = None)\n",
      "     |  \n",
      "     |  log_metrics(self, metrics: Dict[str, Union[torch.Tensor, float]], step: Union[int, NoneType] = None) -> None\n",
      "     |      Log metrics (numeric values) in Neptune runs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          metrics: Dictionary with metric names as keys and measured quantities as values.\n",
      "     |          step: Step number at which the metrics should be recorded, currently ignored.\n",
      "     |  \n",
      "     |  log_text(self, log_name: str, text: str, step: Union[int, NoneType] = None) -> None\n",
      "     |      Log text.\n",
      "     |      \n",
      "     |      Arguments are directly passed to the logger.\n",
      "     |  \n",
      "     |  set_property(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pytorch_lightning.loggers.neptune.NeptuneLogger:\n",
      "     |  \n",
      "     |  experiment\n",
      "     |      Actual Neptune run object. Allows you to use neptune logging features in your\n",
      "     |      :class:`~pytorch_lightning.core.lightning.LightningModule`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          class LitModel(LightningModule):\n",
      "     |              def training_step(self, batch, batch_idx):\n",
      "     |                  # log metrics\n",
      "     |                  acc = ...\n",
      "     |                  self.logger.experiment[\"train/acc\"].log(acc)\n",
      "     |      \n",
      "     |                  # log images\n",
      "     |                  img = ...\n",
      "     |                  self.logger.experiment[\"train/misclassified_images\"].log(File.as_image(img))\n",
      "     |      \n",
      "     |      Note that syntax: ``self.logger.experiment[\"your/metadata/structure\"].log(metadata)``\n",
      "     |      is specific to Neptune and it extends logger capabilities.\n",
      "     |      Specifically, it allows you to log various types of metadata like scores, files,\n",
      "     |      images, interactive visuals, CSVs, etc. Refer to the\n",
      "     |      `Neptune docs <https://docs.neptune.ai/you-should-know/logging-metadata#essential-logging-methods>`_\n",
      "     |      for more detailed explanations.\n",
      "     |      You can also use regular logger methods ``log_metrics()``, and ``log_hyperparams()``\n",
      "     |      with NeptuneLogger as these are also supported.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Return the experiment name or 'offline-name' when exp is run in offline mode.\n",
      "     |  \n",
      "     |  run\n",
      "     |  \n",
      "     |  save_dir\n",
      "     |      Gets the save directory of the experiment which in this case is ``None`` because Neptune does not save\n",
      "     |      locally.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          the root directory where experiment logs get saved\n",
      "     |  \n",
      "     |  version\n",
      "     |      Return the experiment version.\n",
      "     |      \n",
      "     |      It's Neptune Run's short_id\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pytorch_lightning.loggers.neptune.NeptuneLogger:\n",
      "     |  \n",
      "     |  ARTIFACTS_KEY = 'artifacts'\n",
      "     |  \n",
      "     |  LOGGER_JOIN_CHAR = '/'\n",
      "     |  \n",
      "     |  PARAMETERS_KEY = 'hyperparams'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pytorch_lightning.loggers.base.LightningLoggerBase:\n",
      "     |  \n",
      "     |  agg_and_log_metrics(self, metrics: Dict[str, float], step: Union[int, NoneType] = None)\n",
      "     |      Aggregates and records metrics. This method doesn't log the passed metrics instantaneously, but instead\n",
      "     |      it aggregates them and logs only if metrics are ready to be logged.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          metrics: Dictionary with metric names as keys and measured quantities as values\n",
      "     |          step: Step number at which the metrics should be recorded\n",
      "     |  \n",
      "     |  close(self) -> None\n",
      "     |      Do any cleanup that is necessary to close an experiment.\n",
      "     |      \n",
      "     |      See deprecation warning below.\n",
      "     |      \n",
      "     |      .. deprecated:: v1.5\n",
      "     |          This method is deprecated in v1.5 and will be removed in v1.7.\n",
      "     |          Please use `LightningLoggerBase.finalize` instead.\n",
      "     |  \n",
      "     |  log_graph(self, model: 'pl.LightningModule', input_array=None) -> None\n",
      "     |      Record model graph.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          model: lightning model\n",
      "     |          input_array: input passes to `model.forward`\n",
      "     |  \n",
      "     |  save(self) -> None\n",
      "     |      Save log data.\n",
      "     |  \n",
      "     |  update_agg_funcs(self, agg_key_funcs: Union[Mapping[str, Callable[[Sequence[float]], float]], NoneType] = None, agg_default_func: Callable[[Sequence[float]], float] = <function mean at 0x7f85a15b4ee0>)\n",
      "     |      Update aggregation methods.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          agg_key_funcs:\n",
      "     |              Dictionary which maps a metric name to a function, which will\n",
      "     |              aggregate the metric values for the same steps.\n",
      "     |          agg_default_func:\n",
      "     |              Default function to aggregate metric values. If some metric name\n",
      "     |              is not presented in the `agg_key_funcs` dictionary, then the\n",
      "     |              `agg_default_func` will be used for aggregation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pytorch_lightning.loggers.base.LightningLoggerBase:\n",
      "     |  \n",
      "     |  group_separator\n",
      "     |      Return the default separator used by the logger to group the data into subfolders.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pytorch_lightning.loggers.base.LightningLoggerBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['NeptuneLoggerCkpt']\n",
      "\n",
      "FILE\n",
      "    /Users/ldalessi/REPOS/tissue_purifier/src/tissue_purifier/models/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tp.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import seaborn\n",
    "import tarfile\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from anndata import read_h5ad\n",
    "\n",
    "# import tissue purifier\n",
    "import tissue_purifier as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-logic",
   "metadata": {},
   "source": [
    "### Download and untar the example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bd8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tissue_purifier.io\n",
    "\n",
    "bucket_name = \"ld-data-bucket\"\n",
    "data_source_path = \"tissue-purifier/slideseq_testis_anndata_h5ad.tar.gz\"\n",
    "data_destination_path = \"./slideseq_testis_anndata_h5ad.tar.gz\"\n",
    "data_destination_folder = \"./testis_anndata\"\n",
    "\n",
    "# download data from google bucket\n",
    "# tp.io.download_from_bucket(bucket_name, data_source_path, data_destination_path)\n",
    "\n",
    "# untar the data\n",
    "with tarfile.open(data_destination_path, \"r:gz\") as fp:\n",
    "    fp.extractall(path=data_destination_folder)\n",
    "\n",
    "# Make a list of all the h5ad files in the data_destination_folder\n",
    "fname_list = []\n",
    "for f in os.listdir(data_destination_folder):\n",
    "    if f.endswith('.h5ad'):\n",
    "        fname_list.append(f)\n",
    "print(fname_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd32b97",
   "metadata": {},
   "source": [
    "At this point we have a folder with six 'h5ad' files corresponding to different tissues "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b262c4",
   "metadata": {},
   "source": [
    "### Visualize the six anndata as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15060213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the anndata\n",
    "\n",
    "anndata_list = []\n",
    "for fname in fname_list:\n",
    "    anndata = read_h5ad(os.path.join(data_destination_folder, fname))\n",
    "    print(\"Loaded {}\".format(fname))\n",
    "    anndata_list.append(anndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684d283",
   "metadata": {},
   "source": [
    "Each anndata contains the gene expression of ~20K genes for ~30K cells. \\\n",
    "Moreover each cell has 3 annotations: 'x' and 'y' coordinates and 'cell_type' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "anndata_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2b17e",
   "metadata": {},
   "source": [
    "Plot the cell_types in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23523a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols=3\n",
    "nrows=2\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(6*ncols,6*nrows))\n",
    "\n",
    "# Define an consistent mapping from cell_type and color for all the plots\n",
    "cell_types = numpy.asarray(anndata_list[0].obs['cell_type'].values)\n",
    "unique_cell_types = numpy.unique(cell_types)\n",
    "\n",
    "n = -1\n",
    "for r in range(nrows):\n",
    "    for c in range(ncols):\n",
    "        n += 1\n",
    "        anndata_tmp = anndata_list[n]\n",
    "        cell_types = numpy.asarray(anndata_tmp.obs['cell_type'].values)\n",
    "        x = numpy.asarray(anndata_tmp.obs['x'].values)\n",
    "        y = numpy.asarray(anndata_tmp.obs['y'].values) \n",
    "        seaborn.scatterplot(x=x, y=y, hue=cell_types, ax=axes[r,c], size=numpy.ones_like(x), sizes=(10, 10), hue_order=unique_cell_types) \n",
    "        _ = axes[r,c].set_title(fname_list[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840df633",
   "metadata": {},
   "source": [
    "Plot the cell_type counts in all the tissues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels_rotation = 90\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(6*ncols,6*nrows))\n",
    "n = -1\n",
    "for r in range(nrows):\n",
    "    for c in range(ncols):\n",
    "        n += 1\n",
    "        counts = anndata_list[n].obs[\"cell_type\"].value_counts(sort=False)\n",
    "        x = numpy.asarray(counts.index)\n",
    "        y = counts.to_numpy()\n",
    "        _ = seaborn.barplot(x=x, y=y, ax=axes[r,c])\n",
    "        x_labels_raw = axes[r,c].get_xticklabels()\n",
    "        axes[r,c].set_xticklabels(labels=x_labels_raw, rotation=x_labels_rotation)\n",
    "        _ = axes[r,c].set_title(fname_list[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e401d",
   "metadata": {},
   "source": [
    "### Instantiate the DataModule (i.e. define train/test/val dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879bc8b",
   "metadata": {},
   "source": [
    "Here we use the defaults parameters for the datamodule and only define:\n",
    "1. The mapping from cell_type to channels in the image. Each channel will represent the density of a specific cell_type. In some situation it may make sense to map multiple cell-types to the same channel. For example CD4+ and CD4- cells might be mapped to the same channel. \n",
    "2. The folder with the anndata h5ad files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8365c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.data import AnndataFolderDM\n",
    "\n",
    "n_unique_cell_types = len(unique_cell_types)\n",
    "categories_to_channels = dict(zip(unique_cell_types, range(n_unique_cell_types)))\n",
    "print(categories_to_channels)\n",
    "\n",
    "config_dm = tp.data.AnndataFolderDM.get_default_params() # get the defaults parameters\n",
    "config_dm[\"root\"] = data_destination_folder  # specify the folder with the anndata h5ad files\n",
    "config_dm[\"categories_to_channels\"] = categories_to_channels  # specify the mapping between cell_types and channels\n",
    "\n",
    "dm = tp.data.AnndataFolderDM(**config_dm)\n",
    "\n",
    "config_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b9d06",
   "metadata": {},
   "source": [
    "### Instantiate the Model\n",
    "\n",
    "Here we use the Barlow but the same apporach works for Dino, Vae, Simclr\n",
    "\n",
    "We use the defaults parameters and only change the number of input channels of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.models import Barlow\n",
    "# from tissue_purifier.models import Simclr\n",
    "# from tissue_purifier.models import Dino\n",
    "# from tissue_purifier.models import Vae\n",
    "\n",
    "config_model = tp.models.Barlow.get_default_params()  # get the default parameters\n",
    "config_model['image_in_ch'] = dm.ch_in  # specify the number of input channels consistently with datamodule\n",
    "config_model\n",
    "\n",
    "# DO NOT DO THIS\n",
    "# model = tp.models.Barlow(**config_model)  \n",
    "# This will work but the resulting checkpoint will not include the configuration of the datamodule and the \n",
    "# resulting ckpt file will be \"incomplete\".\n",
    "\n",
    "# DO THIS INSTEAD\n",
    "config_model.update(config_dm)  # concatenate the two configuration dictionaries\n",
    "model = tp.models.Barlow(**config_model)  \n",
    "# Now the checkpoint contains the full information to reproduce the simulation.\n",
    "# To reproduce the results in the paper you need to use the config.yaml file provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3a7da",
   "metadata": {},
   "source": [
    "### Train the model and save the final checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from tissue_purifier.models import NeptuneLoggerCkpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(seed=0, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2032e",
   "metadata": {},
   "source": [
    "We use Neptune to log our results. \\\n",
    "Here Neptune is run in the 'offline' mode and the logs are written to local disk. \\\n",
    "Neptune can run in 'async' mode and the results will be saved on a remote database with a nice graphic interface. \\\n",
    "For the 'async' option to work you need to sign up for a free account and provide the correct project and api_key. \\\n",
    "See https://docs.neptune.ai/ for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a64ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_neptune_logger = NeptuneLoggerCkpt(\n",
    "    api_key=\"ANONYMOUS\",  # replace with your own\n",
    "    project='cellarium/tissue-purifier', # replace with your own\n",
    "    run=None,  # if None a new run will be logged. If the run is provided the result will be appended to existing run  \n",
    "    log_model_checkpoints=True, \n",
    "    mode=\"offline\",  # \"async\"\n",
    "    tags=[\"test\"],\n",
    "    fail_on_exception=True,  \n",
    ")\n",
    "\n",
    "# Save the checkpoint periodically during training\n",
    "ckpt_train = ModelCheckpoint(\n",
    "    save_weights_only=False,\n",
    "    save_on_train_epoch_end=True,\n",
    "    save_last=True,\n",
    "    every_n_epochs=3,\n",
    ")\n",
    "    \n",
    "# Define the trainer\n",
    "pl_trainer = Trainer(\n",
    "    weights_save_path=\"saved_ckpt\",\n",
    "    callbacks=[ckpt_train],\n",
    "    gpus=torch.cuda.device_count(),  # number of gpu cards on a single machine to use\n",
    "    check_val_every_n_epoch=10,\n",
    "    num_sanity_val_steps=0,\n",
    "    max_epochs=1, #config_model[\"max_epochs\"],  # run for a single epoch\n",
    "    logger=pl_neptune_logger,\n",
    "    log_every_n_steps=100,\n",
    "    sync_batchnorm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276cf55",
   "metadata": {},
   "source": [
    "### Save the final checkpoint. \n",
    "\n",
    "Since the model was instantiate using a dictionary containing all the parameters (both for model and datamodule) the checkpoint is complete. \\\n",
    "A single checkpoint file contains all the information needded to reproduce the simulation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660724cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_trainer.save_checkpoint(\"ckpt_barlow.pt\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc92ce73",
   "metadata": {},
   "source": [
    "### Visualize the crops used for training  as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c748d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.plots import show_raw_all_channels, show_raw_one_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ca0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()  # get the train_dataloader from the datamodule\n",
    "batch = next(iter(train_loader))  # get one batch from the dataloader\n",
    "list_sp_imgs, list_labels, list_metadata = batch  # batch consists of 3 lists: sparse_images, labels, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f9e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_examples = 5  # number of distinct crops\n",
    "n_augmentations = 3  # apply the random data augmentation this many times\n",
    "\n",
    "all_imgs = []\n",
    "for n in range(n_augmentations):\n",
    "    imgs_tmp = dm.trsfm_train_global(list_sp_imgs[:n_examples])  # apply the data augmentations\n",
    "    all_imgs.append(imgs_tmp)\n",
    "    \n",
    "imgs_train = torch.cat(all_imgs, dim=0)\n",
    "print(\"imgs_train.shape ->\", imgs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column is a different patch\n",
    "# Each row is a different instance of the random data-augmentation\n",
    "\n",
    "titles = []\n",
    "for r in range(n_augmentations):\n",
    "    for c in range(n_examples):\n",
    "        titles.append(\"crop = {}, augmentation = {}\".format(c,r))\n",
    "\n",
    "train_all_ch_fig = show_raw_all_channels(imgs_train, \n",
    "                                         cmap=\"viridis\", \n",
    "                                         n_col=n_examples, \n",
    "                                         figsize=(4*n_examples, 4*n_augmentations), \n",
    "                                         sup_title=\"Train crops, all channels\",\n",
    "                                        titles=titles)\n",
    "train_all_ch_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4133e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_ch_fig = show_raw_one_channel(imgs_train[0], \n",
    "                                        n_col=3,  \n",
    "                                        sup_title=\"One crop used for training\",\n",
    "                                        titles=list(unique_cell_types))\n",
    "train_one_ch_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcaa79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
