{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "careful-warner",
   "metadata": {},
   "source": [
    "# Download and visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-health",
   "metadata": {},
   "source": [
    "This notebook shows how to download public data from dropbox to the local machine and do basic manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-velvet",
   "metadata": {},
   "source": [
    "### Add the src folder to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(root_path, \"src\")\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tissue_purifier.data_utils.datamodule import SlideSeqTestisDM\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser = SlideSeqTestisDM.add_datamodule_specific_args(parser)\n",
    "(args, _) = parser.parse_known_args()\n",
    "\n",
    "dm = SlideSeqTestisDM(**args.__dict__)\n",
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-ferry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-journalist",
   "metadata": {},
   "source": [
    "### Read in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "pca = PCA(n_components=1)\n",
    "X_new = pca.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.scatter(X_new[:, 0], np.ones_like(X_new[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-panic",
   "metadata": {},
   "source": [
    "### Following https://en.wikipedia.org/wiki/Principal_component_analysis#Limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. z_score\n",
    "# 2. covariance\n",
    "# 3. svd \n",
    "# 4. multiplication by few columns of V\n",
    "\n",
    "\n",
    "  # for each feature, remove mean and scale by variance\n",
    "import numpy\n",
    "\n",
    "def get_z_score(x: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    std, mean = torch.std_mean(x, dim=dim, unbiased=True, keepdim=True)\n",
    "    return (x-mean)/std\n",
    "\n",
    "\n",
    "def pca_mine(embeddings, n_components, z_score):\n",
    "    if z_score:\n",
    "        embeddings = get_z_score(embeddings, dim=-2)\n",
    "    else:\n",
    "        embeddings = embeddings - torch.mean(embeddings, dim=-2, keepdim=True)\n",
    "        \n",
    "    cov = torch.einsum('np,nq -> pq', embeddings, embeddings) / (embeddings.shape[0]-1)  # compute the p x p covariance matrix\n",
    "    U, S, Vh = torch.linalg.svd(cov, full_matrices=True)\n",
    "    M = U[:, :n_components]\n",
    "    return torch.einsum('np,pq -> nq', embeddings, M)\n",
    "    \n",
    "    \n",
    "def pca_sklearn(embeddings, n_components, z_score):\n",
    "    if z_score:\n",
    "        embeddings = get_z_score(embeddings, dim=-2)\n",
    "    else:\n",
    "        embeddings = embeddings - torch.mean(embeddings, dim=-2, keepdim=True)\n",
    "    \n",
    "    return PCA(n_components=n_components, random_state=0).fit_transform(embeddings.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample, n_feature = 60, 256\n",
    "X = torch.randn((n_sample, n_feature))\n",
    "#X = torch.tensor([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]]).float()\n",
    "\n",
    "y1 = pca_mine(X, n_components=2, z_score=True)\n",
    "y2 = pca_sklearn(X, n_components=2, z_score=True)\n",
    "\n",
    "print(y1[:10])\n",
    "print(y2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], label='X')\n",
    "plt.scatter(y1[:,0], y1[:,1], label='y1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y1[:,0], y1[:,1], label='y1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y2[:,0], y2[:,1], label='y2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(y1, 3*torch.ones_like(y1), label='y1')\n",
    "plt.scatter(y2, 4*torch.ones_like(y1), label='y2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_new[:, 0], X_new[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-shell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
