{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "split-cleaner",
   "metadata": {},
   "source": [
    "# Evaluate ALL features\n",
    "\n",
    "Similar to notebook 3 we package everything inside a for loop to evaluate all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1201329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REMOVE when notebook is stable\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-logic",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "living-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import seaborn\n",
    "import tarfile\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from anndata import read_h5ad\n",
    "\n",
    "# tissue_purifier import\n",
    "import tissue_purifier as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e0252",
   "metadata": {},
   "source": [
    "### Download the annotated anndata object \n",
    "\n",
    "Altenatively you can use the anndata files generated by running notebook2_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unique-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anndata_sick3.h5ad', 'anndata_sick1.h5ad', 'anndata_sick2.h5ad', 'anndata_wt2.h5ad', 'anndata_wt1.h5ad', 'anndata_wt3.h5ad']\n"
     ]
    }
   ],
   "source": [
    "import tissue_purifier.io\n",
    "\n",
    "bucket_name = \"ld-data-bucket\"\n",
    "annotated_anndata_source_path = \"tissue-purifier/annotated_slideseq_testis_anndata_h5ad.tar.gz\"\n",
    "annotated_anndata_dest_path = \"./annotated_slideseq_testis_anndata_h5ad.tar.gz\"\n",
    "annotated_anndata_dest_folder = \"./testis_anndata_annotated\"\n",
    "\n",
    "#tp.io.download_from_bucket(bucket_name, annotated_anndata_source_path, annotated_anndata_dest_path)   \n",
    "#with tarfile.open(annotated_anndata_dest_path, \"r:gz\") as fp:\n",
    "#    fp.extractall(path=annotated_anndata_dest_folder)\n",
    "    \n",
    "# Make a list of all the h5ad files in the annotated_anndata_dest_folder\n",
    "fname_list = []\n",
    "for f in os.listdir(annotated_anndata_dest_folder):\n",
    "    if f.endswith('.h5ad'):\n",
    "        fname_list.append(f)\n",
    "print(fname_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db1d68",
   "metadata": {},
   "source": [
    "### Decide how to filter the anndata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2886b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cells parameters\n",
    "fc_bc_min_umi = 200                  # filter cells with too few UMI\n",
    "fc_bc_max_umi = 3000                 # filter cells with too many UMI\n",
    "fc_bc_min_n_genes_by_counts = 10     # filter cells with too few GENES\n",
    "fc_bc_max_n_genes_by_counts = 2500   # filter cells with too many GENES\n",
    "fc_bc_max_pct_counts_mt = 5          # filter cells with mitocrondial fraction too high\n",
    "\n",
    "# filter genes parameters\n",
    "fg_bc_min_cells_by_counts = 3000      # filter genes which appear in too few CELLS\n",
    "\n",
    "# filter rare cell types parameters\n",
    "fctype_bc_min_cells_absolute = 100   # filter cell-types which are too RARE in absolute number\n",
    "fctype_bc_min_cells_frequency = 0.01 # filter cell-types which are too RARE in relative abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff84026",
   "metadata": {},
   "source": [
    "### Open the first annotated anndata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a4538e-38ae-444a-9a38-aa0170169354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 33441 × 23514\n",
       "    obs: 'x', 'y', 'cell_type'\n",
       "    obsm: 'barlow', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = read_h5ad(filename=os.path.join(annotated_anndata_dest_folder, fname_list[0]))\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852f24c-9269-4208-a9bf-69d85507896b",
   "metadata": {},
   "source": [
    "### compute few metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62b476e-ff96-4a34-801f-26593d67146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             counts     freqs\n",
      "categories                   \n",
      "ES            12552  0.375348\n",
      "Endothelial     417  0.012470\n",
      "Leydig          340  0.010167\n",
      "Macrophage      623  0.018630\n",
      "Myoid           969  0.028976\n",
      "RS             6780  0.202745\n",
      "SPC            8069  0.241291\n",
      "SPG            2238  0.066924\n",
      "Sertoli        1453  0.043450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 33441 × 23514\n",
       "    obs: 'x', 'y', 'cell_type', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'keep_ctype'\n",
       "    var: 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n",
       "    obsm: 'barlow', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "cell_type_key = \"cell_type\"\n",
    "\n",
    "# mitocondria metrics\n",
    "adata.var['mt'] = adata.var_names.str.startswith('mt-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "# counts cells frequency\n",
    "tmp = adata.obs[cell_type_key].values.describe()\n",
    "print(tmp)\n",
    "mask1 = (tmp[\"counts\"] > fctype_bc_min_cells_absolute)\n",
    "mask2 = (tmp[\"freqs\"] > fctype_bc_min_cells_frequency)\n",
    "mask = mask1 * mask2\n",
    "cell_type_keep = set(tmp[mask].index.values)\n",
    "adata.obs[\"keep_ctype\"] = adata.obs[\"cell_type\"].apply(lambda x: x in cell_type_keep)\n",
    "\n",
    "# Note that adata has extra annotation now\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f13f2",
   "metadata": {},
   "source": [
    "### Filter out cells, genes and cell-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec3d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs[\"total_counts\"] > fc_bc_min_umi, :] \n",
    "adata = adata[adata.obs[\"total_counts\"] < fc_bc_max_umi, :] \n",
    "adata = adata[adata.obs[\"n_genes_by_counts\"] > fc_bc_min_n_genes_by_counts, :] \n",
    "adata = adata[adata.obs[\"n_genes_by_counts\"] < fc_bc_max_n_genes_by_counts, :] \n",
    "adata = adata[adata.obs[\"pct_counts_mt\"] < fc_bc_max_pct_counts_mt, :]\n",
    "adata = adata[adata.obs[\"keep_ctype\"] == True, :]\n",
    "adata = adata[:, adata.var[\"n_cells_by_counts\"] > fg_bc_min_cells_by_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53534ab-1842-435e-808d-254e48d59be0",
   "metadata": {},
   "source": [
    "# Loop to train multiple gene_regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff962c9-870d-463d-a732-8d2769be2698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barlow_pca\n",
      "no regularizations\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 21282260.0000\n",
      "[iter 100]  loss: 21593164.0000\n",
      "[iter 200]  loss: 21511520.0000\n",
      "[iter 300]  loss: 21511872.0000\n",
      "[iter 400]  loss: 21744888.0000\n",
      "[iter 500]  loss: 21766524.0000\n",
      "[iter 600]  loss: 21555148.0000\n",
      "[iter 700]  loss: 21516384.0000\n",
      "[iter 800]  loss: 21813180.0000\n",
      "[iter 900]  loss: 21350082.0000\n",
      "[iter 1000]  loss: 21245302.0000\n",
      "[iter 1100]  loss: 21284488.0000\n",
      "[iter 1200]  loss: 21101572.0000\n",
      "[iter 1300]  loss: 21653532.0000\n",
      "[iter 1400]  loss: 20838996.0000\n",
      "[iter 1500]  loss: 21221020.0000\n",
      "[iter 1600]  loss: 21411156.0000\n",
      "[iter 1700]  loss: 21481326.0000\n",
      "[iter 1800]  loss: 21480472.0000\n",
      "[iter 1900]  loss: 21494240.0000\n",
      "[iter 2000]  loss: 21225648.0000\n",
      "[iter 2100]  loss: 21219120.0000\n",
      "[iter 2200]  loss: 21686632.0000\n",
      "[iter 2300]  loss: 21728286.0000\n",
      "[iter 2400]  loss: 21218912.0000\n",
      "[iter 2500]  loss: 21428094.0000\n",
      "[iter 2600]  loss: 21401528.0000\n",
      "[iter 2700]  loss: 21463344.0000\n",
      "[iter 2800]  loss: 21955412.0000\n",
      "[iter 2900]  loss: 21299986.0000\n",
      "[iter 3000]  loss: 21490482.0000\n",
      "[iter 3100]  loss: 21453822.0000\n",
      "[iter 3200]  loss: 21702254.0000\n",
      "[iter 3300]  loss: 21687084.0000\n",
      "[iter 3400]  loss: 21648080.0000\n",
      "[iter 3500]  loss: 21600398.0000\n",
      "[iter 3600]  loss: 21403224.0000\n",
      "[iter 3700]  loss: 21427400.0000\n",
      "[iter 3800]  loss: 21515388.0000\n",
      "[iter 3900]  loss: 21724410.0000\n",
      "[iter 4000]  loss: 21539970.0000\n",
      "[iter 4100]  loss: 21466316.0000\n",
      "[iter 4200]  loss: 21648496.0000\n",
      "[iter 4300]  loss: 21277228.0000\n",
      "[iter 4400]  loss: 21818100.0000\n",
      "[iter 4500]  loss: 21442966.0000\n",
      "[iter 4600]  loss: 21789152.0000\n",
      "[iter 4700]  loss: 21348442.0000\n",
      "[iter 4800]  loss: 21459440.0000\n",
      "[iter 4900]  loss: 21515432.0000\n",
      "[iter 5000]  loss: 21630476.0000\n",
      "Training completed in 582.7301113605499 seconds\n",
      "saved file gr_ckpt/gr_barlow_pca_no_regularization.pt\n",
      "l1 regularization 0.01\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 22082683.0000\n",
      "[iter 100]  loss: 22160313.9375\n",
      "[iter 200]  loss: 22465413.7500\n",
      "[iter 300]  loss: 21634493.8125\n",
      "[iter 400]  loss: 22003457.7500\n",
      "[iter 500]  loss: 22269297.6250\n",
      "[iter 600]  loss: 22253057.3750\n",
      "[iter 700]  loss: 22476665.5625\n",
      "[iter 800]  loss: 22032029.3750\n",
      "[iter 900]  loss: 22193533.4375\n",
      "[iter 1000]  loss: 22115019.3750\n",
      "[iter 1100]  loss: 22006077.3125\n",
      "[iter 1200]  loss: 21848705.2500\n",
      "[iter 1300]  loss: 22106809.1250\n",
      "[iter 1400]  loss: 22230909.2500\n",
      "[iter 1500]  loss: 22300149.0000\n",
      "[iter 1600]  loss: 22015397.0625\n",
      "[iter 1700]  loss: 22047232.9375\n",
      "[iter 1800]  loss: 22171621.0000\n",
      "[iter 1900]  loss: 22228243.0625\n",
      "[iter 2000]  loss: 22130754.6250\n",
      "[iter 2100]  loss: 22441272.7500\n",
      "[iter 2200]  loss: 22194900.8125\n",
      "[iter 2300]  loss: 21760698.8125\n",
      "[iter 2400]  loss: 21966734.8125\n",
      "[iter 2500]  loss: 21994846.5625\n",
      "[iter 2600]  loss: 22140122.6250\n",
      "[iter 2700]  loss: 22099456.6250\n",
      "[iter 2800]  loss: 22400282.5000\n",
      "[iter 2900]  loss: 22035448.5625\n",
      "[iter 3000]  loss: 22155180.5000\n",
      "[iter 3100]  loss: 22079964.5625\n",
      "[iter 3200]  loss: 22639900.4375\n",
      "[iter 3300]  loss: 21957452.4375\n",
      "[iter 3400]  loss: 22468248.3125\n",
      "[iter 3500]  loss: 22094200.3750\n",
      "[iter 3600]  loss: 21973800.4375\n",
      "[iter 3700]  loss: 22539032.3750\n",
      "[iter 3800]  loss: 22214972.3750\n",
      "[iter 3900]  loss: 22105966.1875\n",
      "[iter 4000]  loss: 22154392.3125\n",
      "[iter 4100]  loss: 22158320.1250\n",
      "[iter 4200]  loss: 22249796.3125\n",
      "[iter 4300]  loss: 22110144.2500\n",
      "[iter 4400]  loss: 21968684.1875\n",
      "[iter 4500]  loss: 22008228.0625\n",
      "[iter 4600]  loss: 22140106.1250\n",
      "[iter 4700]  loss: 21703476.0625\n",
      "[iter 4800]  loss: 21981764.0625\n",
      "[iter 4900]  loss: 22276492.0625\n",
      "[iter 5000]  loss: 22156743.8125\n",
      "Training completed in 584.7424511909485 seconds\n",
      "saved file gr_ckpt/gr_barlow_pca_l1_0.01.pt\n",
      "dino_pca\n",
      "no regularizations\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 21581912.0000\n",
      "[iter 100]  loss: 21514684.0000\n",
      "[iter 200]  loss: 21914356.0000\n",
      "[iter 300]  loss: 21698520.0000\n",
      "[iter 400]  loss: 21504962.0000\n",
      "[iter 500]  loss: 21465588.0000\n",
      "[iter 600]  loss: 21414180.0000\n",
      "[iter 700]  loss: 21455404.0000\n",
      "[iter 800]  loss: 21348790.0000\n",
      "[iter 900]  loss: 21370060.0000\n",
      "[iter 1000]  loss: 21625090.0000\n",
      "[iter 1100]  loss: 21578052.0000\n",
      "[iter 1200]  loss: 21507142.0000\n",
      "[iter 1300]  loss: 21529176.0000\n",
      "[iter 1400]  loss: 21336736.0000\n",
      "[iter 1500]  loss: 21741854.0000\n",
      "[iter 1600]  loss: 21584964.0000\n",
      "[iter 1700]  loss: 21532560.0000\n",
      "[iter 1800]  loss: 21452376.0000\n",
      "[iter 1900]  loss: 21390708.0000\n",
      "[iter 2000]  loss: 21247296.0000\n",
      "[iter 2100]  loss: 21408848.0000\n",
      "[iter 2200]  loss: 21448006.0000\n",
      "[iter 2300]  loss: 21432492.0000\n",
      "[iter 2400]  loss: 21216562.0000\n",
      "[iter 2500]  loss: 21334136.0000\n",
      "[iter 2600]  loss: 21395092.0000\n",
      "[iter 2700]  loss: 21448084.0000\n",
      "[iter 2800]  loss: 21559360.0000\n",
      "[iter 2900]  loss: 21405194.0000\n",
      "[iter 3000]  loss: 21368476.0000\n",
      "[iter 3100]  loss: 21718040.0000\n",
      "[iter 3200]  loss: 21644024.0000\n",
      "[iter 3300]  loss: 21484580.0000\n",
      "[iter 3400]  loss: 21140652.0000\n",
      "[iter 3500]  loss: 21429296.0000\n",
      "[iter 3600]  loss: 21418684.0000\n",
      "[iter 3700]  loss: 21534964.0000\n",
      "[iter 3800]  loss: 21484628.0000\n",
      "[iter 3900]  loss: 21710968.0000\n",
      "[iter 4000]  loss: 21212844.0000\n",
      "[iter 4100]  loss: 21504268.0000\n",
      "[iter 4200]  loss: 21168990.0000\n",
      "[iter 4300]  loss: 21249934.0000\n",
      "[iter 4400]  loss: 21542862.0000\n",
      "[iter 4500]  loss: 21623012.0000\n",
      "[iter 4600]  loss: 21206576.0000\n",
      "[iter 4700]  loss: 21252720.0000\n",
      "[iter 4800]  loss: 21815246.0000\n",
      "[iter 4900]  loss: 21513630.0000\n",
      "[iter 5000]  loss: 21184488.0000\n",
      "Training completed in 576.1587653160095 seconds\n",
      "saved file gr_ckpt/gr_dino_pca_no_regularization.pt\n",
      "l1 regularization 0.01\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 22200280.9375\n",
      "[iter 100]  loss: 22327911.8750\n",
      "[iter 200]  loss: 22156945.6875\n",
      "[iter 300]  loss: 22167815.7500\n",
      "[iter 400]  loss: 22251337.5000\n",
      "[iter 500]  loss: 22120003.5000\n",
      "[iter 600]  loss: 22313405.4375\n",
      "[iter 700]  loss: 22085261.3750\n",
      "[iter 800]  loss: 22136917.2500\n",
      "[iter 900]  loss: 22373537.3750\n",
      "[iter 1000]  loss: 22043775.4375\n",
      "[iter 1100]  loss: 22317265.2500\n",
      "[iter 1200]  loss: 22073357.1875\n",
      "[iter 1300]  loss: 21943665.2500\n",
      "[iter 1400]  loss: 21831515.1875\n",
      "[iter 1500]  loss: 22031233.1250\n",
      "[iter 1600]  loss: 22293154.8750\n",
      "[iter 1700]  loss: 22165334.9375\n",
      "[iter 1800]  loss: 21899729.0625\n",
      "[iter 1900]  loss: 21874444.9375\n",
      "[iter 2000]  loss: 22058096.7500\n",
      "[iter 2100]  loss: 22150872.8125\n",
      "[iter 2200]  loss: 22347656.7500\n",
      "[iter 2300]  loss: 22043202.6875\n",
      "[iter 2400]  loss: 22445598.7500\n",
      "[iter 2500]  loss: 22336916.6250\n",
      "[iter 2600]  loss: 21607284.8125\n",
      "[iter 2700]  loss: 22056736.7500\n",
      "[iter 2800]  loss: 21908340.7500\n",
      "[iter 2900]  loss: 22135468.5000\n",
      "[iter 3000]  loss: 22036584.5000\n",
      "[iter 3100]  loss: 21979908.6875\n",
      "[iter 3200]  loss: 22077688.5625\n",
      "[iter 3300]  loss: 22311486.3125\n",
      "[iter 3400]  loss: 22445084.5000\n",
      "[iter 3500]  loss: 22263408.4375\n",
      "[iter 3600]  loss: 22256504.2500\n",
      "[iter 3700]  loss: 22366064.2500\n",
      "[iter 3800]  loss: 22188786.2500\n",
      "[iter 3900]  loss: 21919072.0625\n",
      "[iter 4000]  loss: 22132940.3125\n",
      "[iter 4100]  loss: 22162060.2500\n",
      "[iter 4200]  loss: 21929844.1875\n",
      "[iter 4300]  loss: 21781128.0625\n",
      "[iter 4400]  loss: 22415768.1875\n",
      "[iter 4500]  loss: 22102912.0625\n",
      "[iter 4600]  loss: 22218690.1250\n",
      "[iter 4700]  loss: 22297287.9375\n",
      "[iter 4800]  loss: 22198450.0000\n",
      "[iter 4900]  loss: 22328748.1875\n",
      "[iter 5000]  loss: 22432423.9375\n",
      "Training completed in 578.3138253688812 seconds\n",
      "saved file gr_ckpt/gr_dino_pca_l1_0.01.pt\n",
      "simclr_pca\n",
      "no regularizations\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 21720598.0000\n",
      "[iter 100]  loss: 21491142.0000\n",
      "[iter 200]  loss: 21375414.0000\n",
      "[iter 300]  loss: 21332406.0000\n",
      "[iter 400]  loss: 21477068.0000\n",
      "[iter 500]  loss: 21291000.0000\n",
      "[iter 600]  loss: 21888400.0000\n",
      "[iter 700]  loss: 21572500.0000\n",
      "[iter 800]  loss: 21615788.0000\n",
      "[iter 900]  loss: 21388350.0000\n",
      "[iter 1000]  loss: 21290892.0000\n",
      "[iter 1100]  loss: 21509168.0000\n",
      "[iter 1200]  loss: 21600836.0000\n",
      "[iter 1300]  loss: 21322148.0000\n",
      "[iter 1400]  loss: 21387036.0000\n",
      "[iter 1500]  loss: 21722772.0000\n",
      "[iter 1600]  loss: 21782124.0000\n",
      "[iter 1700]  loss: 21287488.0000\n",
      "[iter 1800]  loss: 21584092.0000\n",
      "[iter 1900]  loss: 21429020.0000\n",
      "[iter 2000]  loss: 21404620.0000\n",
      "[iter 2100]  loss: 21481308.0000\n",
      "[iter 2200]  loss: 21187028.0000\n",
      "[iter 2300]  loss: 21389212.0000\n",
      "[iter 2400]  loss: 21122936.0000\n",
      "[iter 2500]  loss: 21306012.0000\n",
      "[iter 2600]  loss: 21417624.0000\n",
      "[iter 2700]  loss: 21346314.0000\n",
      "[iter 2800]  loss: 21396852.0000\n",
      "[iter 2900]  loss: 21859482.0000\n",
      "[iter 3000]  loss: 21445150.0000\n",
      "[iter 3100]  loss: 21837368.0000\n",
      "[iter 3200]  loss: 21147104.0000\n",
      "[iter 3300]  loss: 21220372.0000\n",
      "[iter 3400]  loss: 21496020.0000\n",
      "[iter 3500]  loss: 21387890.0000\n",
      "[iter 3600]  loss: 21184266.0000\n",
      "[iter 3700]  loss: 21183616.0000\n",
      "[iter 3800]  loss: 21613820.0000\n",
      "[iter 3900]  loss: 21258918.0000\n",
      "[iter 4000]  loss: 21419568.0000\n",
      "[iter 4100]  loss: 21620640.0000\n",
      "[iter 4200]  loss: 21283940.0000\n",
      "[iter 4300]  loss: 21680098.0000\n",
      "[iter 4400]  loss: 21499246.0000\n",
      "[iter 4500]  loss: 21563644.0000\n",
      "[iter 4600]  loss: 21489184.0000\n",
      "[iter 4700]  loss: 21204728.0000\n",
      "[iter 4800]  loss: 21728568.0000\n",
      "[iter 4900]  loss: 21558508.0000\n",
      "[iter 5000]  loss: 21528588.0000\n",
      "Training completed in 571.743479013443 seconds\n",
      "saved file gr_ckpt/gr_simclr_pca_no_regularization.pt\n",
      "l1 regularization 0.01\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 22436179.0000\n",
      "[iter 100]  loss: 22100021.5000\n",
      "[iter 200]  loss: 22381021.6250\n",
      "[iter 300]  loss: 22153561.5625\n",
      "[iter 400]  loss: 22222093.3750\n",
      "[iter 500]  loss: 22816633.4375\n",
      "[iter 600]  loss: 22123019.5000\n",
      "[iter 700]  loss: 22368923.3125\n",
      "[iter 800]  loss: 22237875.1875\n",
      "[iter 900]  loss: 22398089.1250\n",
      "[iter 1000]  loss: 22161207.1250\n",
      "[iter 1100]  loss: 22083787.1250\n",
      "[iter 1200]  loss: 21886307.1250\n",
      "[iter 1300]  loss: 22143433.0625\n",
      "[iter 1400]  loss: 22206261.1250\n",
      "[iter 1500]  loss: 22348708.8750\n",
      "[iter 1600]  loss: 22192194.8750\n",
      "[iter 1700]  loss: 21986804.8750\n",
      "[iter 1800]  loss: 22050730.8125\n",
      "[iter 1900]  loss: 21919490.8750\n",
      "[iter 2000]  loss: 22013972.7500\n",
      "[iter 2100]  loss: 22190590.6250\n",
      "[iter 2200]  loss: 22219904.6875\n",
      "[iter 2300]  loss: 22210928.5625\n",
      "[iter 2400]  loss: 22364316.6250\n",
      "[iter 2500]  loss: 21718484.5000\n",
      "[iter 2600]  loss: 21909960.6250\n",
      "[iter 2700]  loss: 22565340.5000\n",
      "[iter 2800]  loss: 22509256.3125\n",
      "[iter 2900]  loss: 22254000.4375\n",
      "[iter 3000]  loss: 22300498.3125\n",
      "[iter 3100]  loss: 21709346.3750\n",
      "[iter 3200]  loss: 22141424.2500\n",
      "[iter 3300]  loss: 22032008.2500\n",
      "[iter 3400]  loss: 21852948.2500\n",
      "[iter 3500]  loss: 22481868.3750\n",
      "[iter 3600]  loss: 22348400.2500\n",
      "[iter 3700]  loss: 22335636.1250\n",
      "[iter 3800]  loss: 22492512.0000\n",
      "[iter 3900]  loss: 21779772.1250\n",
      "[iter 4000]  loss: 21959082.1250\n",
      "[iter 4100]  loss: 22006616.0625\n",
      "[iter 4200]  loss: 22193612.0625\n",
      "[iter 4300]  loss: 21873448.0000\n",
      "[iter 4400]  loss: 22598283.9375\n",
      "[iter 4500]  loss: 22266112.0000\n",
      "[iter 4600]  loss: 22212539.9375\n",
      "[iter 4700]  loss: 22164219.7500\n",
      "[iter 4800]  loss: 22374143.7500\n",
      "[iter 4900]  loss: 22108685.7500\n",
      "[iter 5000]  loss: 22296879.8125\n",
      "Training completed in 580.2633719444275 seconds\n",
      "saved file gr_ckpt/gr_simclr_pca_l1_0.01.pt\n",
      "barlow\n",
      "no regularizations\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 23065892.0000\n",
      "[iter 100]  loss: 20968404.0000\n",
      "[iter 200]  loss: 22276324.0000\n",
      "[iter 300]  loss: 22196532.0000\n",
      "[iter 400]  loss: 22461884.0000\n",
      "[iter 500]  loss: 22267168.0000\n",
      "[iter 600]  loss: 23235110.0000\n",
      "[iter 700]  loss: 20994868.0000\n",
      "[iter 800]  loss: 22973904.0000\n",
      "[iter 900]  loss: 21269080.0000\n",
      "[iter 1000]  loss: 23379040.0000\n",
      "[iter 1100]  loss: 21794976.0000\n",
      "[iter 1200]  loss: 20872708.0000\n",
      "[iter 1300]  loss: 21906524.0000\n",
      "[iter 1400]  loss: 22287376.0000\n",
      "[iter 1500]  loss: 21452872.0000\n",
      "[iter 1600]  loss: 22244148.0000\n",
      "[iter 1700]  loss: 21323920.0000\n",
      "[iter 1800]  loss: 22820540.0000\n",
      "[iter 1900]  loss: 21808156.0000\n",
      "[iter 2000]  loss: 23265606.0000\n",
      "[iter 2100]  loss: 22131456.0000\n",
      "[iter 2200]  loss: 21718884.0000\n",
      "[iter 2300]  loss: 21267574.0000\n",
      "[iter 2400]  loss: 20921092.0000\n",
      "[iter 2500]  loss: 23133508.0000\n",
      "[iter 2600]  loss: 22901840.0000\n",
      "[iter 2700]  loss: 23205762.0000\n",
      "[iter 2800]  loss: 21989548.0000\n",
      "[iter 2900]  loss: 21629156.0000\n",
      "[iter 3000]  loss: 21740016.0000\n",
      "[iter 3100]  loss: 22035164.0000\n",
      "[iter 3200]  loss: 22153732.0000\n",
      "[iter 3300]  loss: 22116986.0000\n",
      "[iter 3400]  loss: 22461674.0000\n",
      "[iter 3500]  loss: 21843112.0000\n",
      "[iter 3600]  loss: 21992628.0000\n",
      "[iter 3700]  loss: 22491984.0000\n",
      "[iter 3800]  loss: 22469952.0000\n",
      "[iter 3900]  loss: 22769648.0000\n",
      "[iter 4000]  loss: 22357318.0000\n",
      "[iter 4100]  loss: 22155096.0000\n",
      "[iter 4200]  loss: 23500912.0000\n",
      "[iter 4300]  loss: 22819972.0000\n",
      "[iter 4400]  loss: 22352236.0000\n",
      "[iter 4500]  loss: 22900668.0000\n",
      "[iter 4600]  loss: 20909050.0000\n",
      "[iter 4700]  loss: 22472750.0000\n",
      "[iter 4800]  loss: 22061664.0000\n",
      "[iter 4900]  loss: 23034832.0000\n",
      "[iter 5000]  loss: 22617906.0000\n",
      "Training completed in 1458.8634052276611 seconds\n",
      "saved file gr_ckpt/gr_barlow_no_regularization.pt\n",
      "l1 regularization 0.01\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 61162996.0000\n",
      "[iter 100]  loss: 62419004.0000\n",
      "[iter 200]  loss: 61916172.0000\n",
      "[iter 300]  loss: 61230866.0000\n",
      "[iter 400]  loss: 61599520.0000\n",
      "[iter 500]  loss: 61173022.0000\n",
      "[iter 600]  loss: 62290524.0000\n",
      "[iter 700]  loss: 62487608.0000\n",
      "[iter 800]  loss: 62294034.0000\n",
      "[iter 900]  loss: 61326170.0000\n",
      "[iter 1000]  loss: 62108976.0000\n",
      "[iter 1100]  loss: 62018678.0000\n",
      "[iter 1200]  loss: 61481740.0000\n",
      "[iter 1300]  loss: 61726316.0000\n",
      "[iter 1400]  loss: 61208948.0000\n",
      "[iter 1500]  loss: 61895770.0000\n",
      "[iter 1600]  loss: 61570652.0000\n",
      "[iter 1700]  loss: 62113816.0000\n",
      "[iter 1800]  loss: 61318900.0000\n",
      "[iter 1900]  loss: 61176344.0000\n",
      "[iter 2000]  loss: 61499220.0000\n",
      "[iter 2100]  loss: 60832272.0000\n",
      "[iter 2200]  loss: 61314018.0000\n",
      "[iter 2300]  loss: 61633862.0000\n",
      "[iter 2400]  loss: 62127234.0000\n",
      "[iter 2500]  loss: 61496156.0000\n",
      "[iter 2600]  loss: 61763832.0000\n",
      "[iter 2700]  loss: 61776832.0000\n",
      "[iter 2800]  loss: 61965180.0000\n",
      "[iter 2900]  loss: 60540534.0000\n",
      "[iter 3000]  loss: 61652876.0000\n",
      "[iter 3100]  loss: 60666226.0000\n",
      "[iter 3200]  loss: 61579532.0000\n",
      "[iter 3300]  loss: 61268196.0000\n",
      "[iter 3400]  loss: 60581378.0000\n",
      "[iter 3500]  loss: 61301200.0000\n",
      "[iter 3600]  loss: 61050068.0000\n",
      "[iter 3700]  loss: 62424346.0000\n",
      "[iter 3800]  loss: 60368560.0000\n",
      "[iter 3900]  loss: 60802128.0000\n",
      "[iter 4000]  loss: 61475236.0000\n",
      "[iter 4100]  loss: 60662496.0000\n",
      "[iter 4200]  loss: 60518038.0000\n",
      "[iter 4300]  loss: 60472754.0000\n",
      "[iter 4400]  loss: 59988766.0000\n",
      "[iter 4500]  loss: 60011412.0000\n",
      "[iter 4600]  loss: 60619832.0000\n",
      "[iter 4700]  loss: 62299160.0000\n",
      "[iter 4800]  loss: 61377612.0000\n",
      "[iter 4900]  loss: 62235392.0000\n",
      "[iter 5000]  loss: 60494462.0000\n",
      "Training completed in 1470.2488934993744 seconds\n",
      "saved file gr_ckpt/gr_barlow_l1_0.01.pt\n",
      "dino\n",
      "no regularizations\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 21381360.0000\n",
      "[iter 100]  loss: 21143856.0000\n",
      "[iter 200]  loss: 22075500.0000\n",
      "[iter 300]  loss: 22658326.0000\n",
      "[iter 400]  loss: 21846780.0000\n",
      "[iter 500]  loss: 21592140.0000\n",
      "[iter 600]  loss: 20934530.0000\n",
      "[iter 700]  loss: 21117548.0000\n",
      "[iter 800]  loss: 21566322.0000\n",
      "[iter 900]  loss: 21010532.0000\n",
      "[iter 1000]  loss: 20336388.0000\n",
      "[iter 1100]  loss: 22869564.0000\n",
      "[iter 1200]  loss: 21326050.0000\n",
      "[iter 1300]  loss: 22262696.0000\n",
      "[iter 1400]  loss: 21663620.0000\n",
      "[iter 1500]  loss: 22307140.0000\n",
      "[iter 1600]  loss: 22709272.0000\n",
      "[iter 1700]  loss: 21196984.0000\n",
      "[iter 1800]  loss: 21054092.0000\n",
      "[iter 1900]  loss: 21764724.0000\n",
      "[iter 2000]  loss: 22100960.0000\n",
      "[iter 2100]  loss: 20749860.0000\n",
      "[iter 2200]  loss: 21435412.0000\n",
      "[iter 2300]  loss: 21804010.0000\n",
      "[iter 2400]  loss: 22065548.0000\n",
      "[iter 2500]  loss: 21035678.0000\n",
      "[iter 2600]  loss: 21743920.0000\n",
      "[iter 2700]  loss: 22894412.0000\n",
      "[iter 2800]  loss: 21879630.0000\n",
      "[iter 2900]  loss: 20621174.0000\n",
      "[iter 3000]  loss: 21416344.0000\n",
      "[iter 3100]  loss: 22115566.0000\n",
      "[iter 3200]  loss: 21680896.0000\n",
      "[iter 3300]  loss: 21187380.0000\n",
      "[iter 3400]  loss: 21332304.0000\n",
      "[iter 3500]  loss: 22270944.0000\n",
      "[iter 3600]  loss: 20684296.0000\n",
      "[iter 3700]  loss: 20596566.0000\n",
      "[iter 3800]  loss: 21265648.0000\n",
      "[iter 3900]  loss: 21679442.0000\n",
      "[iter 4000]  loss: 21966072.0000\n",
      "[iter 4100]  loss: 22695764.0000\n",
      "[iter 4200]  loss: 20812628.0000\n",
      "[iter 4300]  loss: 21653530.0000\n",
      "[iter 4400]  loss: 20908540.0000\n",
      "[iter 4500]  loss: 22032932.0000\n",
      "[iter 4600]  loss: 22605728.0000\n",
      "[iter 4700]  loss: 21861844.0000\n",
      "[iter 4800]  loss: 21396394.0000\n",
      "[iter 4900]  loss: 23069420.0000\n",
      "[iter 5000]  loss: 22112200.0000\n",
      "Training completed in 1457.5100376605988 seconds\n",
      "saved file gr_ckpt/gr_dino_no_regularization.pt\n",
      "l1 regularization 0.01\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 60920456.0000\n",
      "[iter 100]  loss: 61539440.0000\n",
      "[iter 200]  loss: 61288432.0000\n",
      "[iter 300]  loss: 61140590.0000\n",
      "[iter 400]  loss: 60120532.0000\n",
      "[iter 500]  loss: 60682832.0000\n",
      "[iter 600]  loss: 61762220.0000\n",
      "[iter 700]  loss: 62249496.0000\n",
      "[iter 800]  loss: 60193822.0000\n",
      "[iter 900]  loss: 59752992.0000\n",
      "[iter 1000]  loss: 60376576.0000\n",
      "[iter 1100]  loss: 62320448.0000\n",
      "[iter 1200]  loss: 60752284.0000\n",
      "[iter 1300]  loss: 59923124.0000\n",
      "[iter 1400]  loss: 60258520.0000\n",
      "[iter 1500]  loss: 61060334.0000\n",
      "[iter 1600]  loss: 61292964.0000\n",
      "[iter 1700]  loss: 61511088.0000\n",
      "[iter 1800]  loss: 60325260.0000\n",
      "[iter 1900]  loss: 60933928.0000\n",
      "[iter 2000]  loss: 61800418.0000\n",
      "[iter 2100]  loss: 60659390.0000\n",
      "[iter 2200]  loss: 61009740.0000\n",
      "[iter 2300]  loss: 61230930.0000\n",
      "[iter 2400]  loss: 60237280.0000\n",
      "[iter 2500]  loss: 60776864.0000\n",
      "[iter 2600]  loss: 60556538.0000\n",
      "[iter 2700]  loss: 62091224.0000\n",
      "[iter 2800]  loss: 60869608.0000\n",
      "[iter 2900]  loss: 61584044.0000\n",
      "[iter 3000]  loss: 60591690.0000\n",
      "[iter 3100]  loss: 61700642.0000\n",
      "[iter 3200]  loss: 60209756.0000\n",
      "[iter 3300]  loss: 60921870.0000\n",
      "[iter 3400]  loss: 60996246.0000\n",
      "[iter 3500]  loss: 61079208.0000\n",
      "[iter 3600]  loss: 60401038.0000\n",
      "[iter 3700]  loss: 61270796.0000\n",
      "[iter 3800]  loss: 61244916.0000\n",
      "[iter 3900]  loss: 59908324.0000\n",
      "[iter 4000]  loss: 61699212.0000\n",
      "[iter 4100]  loss: 60919538.0000\n",
      "[iter 4200]  loss: 61223516.0000\n",
      "[iter 4300]  loss: 60077036.0000\n",
      "[iter 4400]  loss: 62488588.0000\n",
      "[iter 4500]  loss: 60743682.0000\n",
      "[iter 4600]  loss: 61595842.0000\n",
      "[iter 4700]  loss: 61248596.0000\n",
      "[iter 4800]  loss: 60357868.0000\n",
      "[iter 4900]  loss: 60656554.0000\n",
      "[iter 5000]  loss: 61248992.0000\n",
      "Training completed in 1468.7517914772034 seconds\n",
      "saved file gr_ckpt/gr_dino_l1_0.01.pt\n",
      "simclr\n",
      "no regularizations\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 22238508.0000\n",
      "[iter 100]  loss: 22588918.0000\n",
      "[iter 200]  loss: 21721622.0000\n",
      "[iter 300]  loss: 22274202.0000\n",
      "[iter 400]  loss: 21342920.0000\n",
      "[iter 500]  loss: 22639260.0000\n",
      "[iter 600]  loss: 22642338.0000\n",
      "[iter 700]  loss: 23108270.0000\n",
      "[iter 800]  loss: 21360836.0000\n",
      "[iter 900]  loss: 22938560.0000\n",
      "[iter 1000]  loss: 22079432.0000\n",
      "[iter 1100]  loss: 22521204.0000\n",
      "[iter 1200]  loss: 22318458.0000\n",
      "[iter 1300]  loss: 20999960.0000\n",
      "[iter 1400]  loss: 23145490.0000\n",
      "[iter 1500]  loss: 21852360.0000\n",
      "[iter 1600]  loss: 21504936.0000\n",
      "[iter 1700]  loss: 22063324.0000\n",
      "[iter 1800]  loss: 22552238.0000\n",
      "[iter 1900]  loss: 22114176.0000\n",
      "[iter 2000]  loss: 23009168.0000\n",
      "[iter 2100]  loss: 21402920.0000\n",
      "[iter 2200]  loss: 22523380.0000\n",
      "[iter 2300]  loss: 22472278.0000\n",
      "[iter 2400]  loss: 20487134.0000\n",
      "[iter 2500]  loss: 21464584.0000\n",
      "[iter 2600]  loss: 22170562.0000\n",
      "[iter 2700]  loss: 22576714.0000\n",
      "[iter 2800]  loss: 21894540.0000\n",
      "[iter 2900]  loss: 21524640.0000\n",
      "[iter 3000]  loss: 21125412.0000\n",
      "[iter 3100]  loss: 21526016.0000\n",
      "[iter 3200]  loss: 22146962.0000\n",
      "[iter 3300]  loss: 22488010.0000\n",
      "[iter 3400]  loss: 22835120.0000\n",
      "[iter 3500]  loss: 21983042.0000\n",
      "[iter 3600]  loss: 21808576.0000\n",
      "[iter 3700]  loss: 21464904.0000\n",
      "[iter 3800]  loss: 21086776.0000\n",
      "[iter 3900]  loss: 22542312.0000\n",
      "[iter 4000]  loss: 22491136.0000\n",
      "[iter 4100]  loss: 22923070.0000\n",
      "[iter 4200]  loss: 21435178.0000\n",
      "[iter 4300]  loss: 24031538.0000\n",
      "[iter 4400]  loss: 21832964.0000\n",
      "[iter 4500]  loss: 22081600.0000\n",
      "[iter 4600]  loss: 21995228.0000\n",
      "[iter 4700]  loss: 22301742.0000\n",
      "[iter 4800]  loss: 21960980.0000\n",
      "[iter 4900]  loss: 22281300.0000\n",
      "[iter 5000]  loss: 21811840.0000\n",
      "Training completed in 1458.6401233673096 seconds\n",
      "saved file gr_ckpt/gr_simclr_no_regularization.pt\n",
      "l1 regularization 0.01\n",
      "training from pretrained model\n",
      "[iter 1]  loss: 61320082.0000\n",
      "[iter 100]  loss: 60971222.0000\n",
      "[iter 200]  loss: 62411236.0000\n",
      "[iter 300]  loss: 61230512.0000\n",
      "[iter 400]  loss: 61345830.0000\n",
      "[iter 500]  loss: 61170352.0000\n",
      "[iter 600]  loss: 60206532.0000\n",
      "[iter 700]  loss: 61458940.0000\n",
      "[iter 800]  loss: 61915778.0000\n",
      "[iter 900]  loss: 60340010.0000\n",
      "[iter 1000]  loss: 61003716.0000\n",
      "[iter 1100]  loss: 61731982.0000\n",
      "[iter 1200]  loss: 61098372.0000\n",
      "[iter 1300]  loss: 61215392.0000\n",
      "[iter 1400]  loss: 61459192.0000\n",
      "[iter 1500]  loss: 61292152.0000\n",
      "[iter 1600]  loss: 61851796.0000\n",
      "[iter 1700]  loss: 60856904.0000\n",
      "[iter 1800]  loss: 61600232.0000\n",
      "[iter 1900]  loss: 60053744.0000\n",
      "[iter 2000]  loss: 61180446.0000\n",
      "[iter 2100]  loss: 59855106.0000\n",
      "[iter 2200]  loss: 60519474.0000\n",
      "[iter 2300]  loss: 61859064.0000\n",
      "[iter 2400]  loss: 60758008.0000\n",
      "[iter 2500]  loss: 61095722.0000\n",
      "[iter 2600]  loss: 61186554.0000\n",
      "[iter 2700]  loss: 61784410.0000\n",
      "[iter 2800]  loss: 61489894.0000\n",
      "[iter 2900]  loss: 60203856.0000\n",
      "[iter 3000]  loss: 61941658.0000\n",
      "[iter 3100]  loss: 61047122.0000\n",
      "[iter 3200]  loss: 60343788.0000\n",
      "[iter 3300]  loss: 60786044.0000\n",
      "[iter 3400]  loss: 61575984.0000\n",
      "[iter 3500]  loss: 61100514.0000\n",
      "[iter 3600]  loss: 61773056.0000\n",
      "[iter 3700]  loss: 61994900.0000\n",
      "[iter 3800]  loss: 62830324.0000\n",
      "[iter 3900]  loss: 61817396.0000\n",
      "[iter 4000]  loss: 61877432.0000\n",
      "[iter 4100]  loss: 62901928.0000\n",
      "[iter 4200]  loss: 62274932.0000\n",
      "[iter 4300]  loss: 60351360.0000\n",
      "[iter 4400]  loss: 60136318.0000\n",
      "[iter 4500]  loss: 62295660.0000\n",
      "[iter 4600]  loss: 60795204.0000\n",
      "[iter 4700]  loss: 61239808.0000\n",
      "[iter 4800]  loss: 61477284.0000\n",
      "[iter 4900]  loss: 60638984.0000\n",
      "[iter 5000]  loss: 60544004.0000\n",
      "Training completed in 1469.26034116745 seconds\n",
      "saved file gr_ckpt/gr_simclr_l1_0.01.pt\n"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.genex import *\n",
    "gr_ckpt_dir = \"gr_ckpt\"\n",
    "filename_no_covariate = os.path.join(gr_ckpt_dir, \"gr_no_covariate.pt\")\n",
    "\n",
    "covariate_keys = ['barlow_pca', 'dino_pca', 'simclr_pca', 'barlow', 'dino', 'simclr']\n",
    "# covariate_keys = ['ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500']\n",
    "# covariate_keys = ['ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500']\n",
    "\n",
    "n_train_steps_from_scratch = 20000\n",
    "n_train_steps_from_pretrained = 5000\n",
    "# n_train_steps_from_scratch = 10\n",
    "# n_train_steps_from_pretrained = 10\n",
    "\n",
    "l1_strengths = [0.01] #, 0.1, 1.0]\n",
    "l2_strengths = [] # [0.01, 0.1, 1.0]\n",
    "\n",
    "gr = GeneRegression()\n",
    "gr.configure_optimizer(optimizer_type='adam', lr=5E-3)\n",
    "\n",
    "for n_iter, covariate_key in enumerate(covariate_keys):\n",
    "    print(covariate_key)\n",
    "\n",
    "    # decide the subsample size (to fit into GPU memory)\n",
    "    if covariate_key.startswith(\"ncv\") or covariate_key.endswith(\"_pca\"):\n",
    "        subsample_size_cells = 2000\n",
    "    else:\n",
    "        subsample_size_cells = 200 \n",
    "    \n",
    "    \n",
    "    if covariate_key.endswith(\"_pca\"):\n",
    "        \n",
    "        # make gene dataset with PCA\n",
    "        gene_dataset = make_gene_dataset_from_anndata(\n",
    "            anndata=adata,\n",
    "            cell_type_key='cell_type',\n",
    "            covariate_key=covariate_key.split(\"_\")[0],\n",
    "            preprocess_strategy='z_score',\n",
    "            apply_pca=True,\n",
    "            n_components=9,)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # make the dataset without PCA\n",
    "        gene_dataset = make_gene_dataset_from_anndata(\n",
    "            anndata=adata,\n",
    "            cell_type_key='cell_type',\n",
    "            covariate_key=covariate_key,\n",
    "            preprocess_strategy='raw',\n",
    "            apply_pca=False)\n",
    "    \n",
    "    # split into train/test/val (note that we provide the random_state for reproducibility) \n",
    "    train_test_val_dataset = next(iter(train_test_val_split(gene_dataset, random_state=0)))\n",
    "    filename_dataset = os.path.join(gr_ckpt_dir, \"gr_{}_dataset.pt\".format(covariate_key))\n",
    "    torch.save(train_test_val_dataset, filename_dataset)\n",
    "    train_dataset, test_dataset, val_dataset = train_test_val_dataset\n",
    "    \n",
    "    ## only at the very beginning train a model with no_covariance from scratch\n",
    "    #if n_iter == 0:\n",
    "    #    print(\"no covariate\")\n",
    "    #    gr.train(\n",
    "    #        dataset=train_dataset,\n",
    "    #        n_steps=n_train_steps_from_scratch,\n",
    "    #        print_frequency=100,\n",
    "    #        use_covariates=False,\n",
    "    #        l1_regularization_strength=None,\n",
    "    #        l2_regularization_strength=None,\n",
    "    #        eps_range=(1.0E-5, 1.0E-2),\n",
    "    #        subsample_size_cells=subsample_size_cells,\n",
    "    #        subsample_size_genes=None,\n",
    "    #        initialization_type=\"scratch\")\n",
    "    #    gr.save_ckpt(filename_no_covariate)\n",
    "    #    print(\"saved file {}\".format(filename_no_covariate))\n",
    "    \n",
    "    # train with no regularization start from pretrained model with no_covaraince. \n",
    "    # This will make training faster\n",
    "    print(\"no regularizations\")\n",
    "    gr.partial_load_ckpt(filename=filename_no_covariate)\n",
    "    gr.train(\n",
    "        dataset=train_dataset,\n",
    "        n_steps=n_train_steps_from_pretrained,\n",
    "        print_frequency=100,\n",
    "        use_covariates=True,\n",
    "        l1_regularization_strength=None,\n",
    "        l2_regularization_strength=None,\n",
    "        eps_range=(1.0E-5, 1.0E-2),\n",
    "        subsample_size_cells=subsample_size_cells,\n",
    "        subsample_size_genes=None,\n",
    "        initialization_type=\"pretrained\")\n",
    "    filename = os.path.join(gr_ckpt_dir, \"gr_{}_no_regularization.pt\".format(covariate_key))\n",
    "    gr.save_ckpt(filename)\n",
    "    print(\"saved file {}\".format(filename))\n",
    "        \n",
    "    # train with l1 regularization.\n",
    "    # start from pretrained model with no_covaraince. \n",
    "    # This will make training faster\n",
    "    for l1 in l1_strengths: \n",
    "        gr.partial_load_ckpt(filename=filename_no_covariate)\n",
    "        print(\"l1 regularization\", l1)\n",
    "        gr.train(\n",
    "            dataset=train_dataset,\n",
    "            n_steps=n_train_steps_from_pretrained,\n",
    "            print_frequency=100,\n",
    "            use_covariates=True,\n",
    "            l1_regularization_strength=l1,\n",
    "            l2_regularization_strength=None,\n",
    "            eps_range=(1.0E-5, 1.0E-2),\n",
    "            subsample_size_cells=subsample_size_cells,\n",
    "            subsample_size_genes=None,\n",
    "            initialization_type=\"pretrained\")\n",
    "        filename = os.path.join(gr_ckpt_dir, \"gr_{}_l1_{}.pt\".format(covariate_key, l1))\n",
    "        gr.save_ckpt(filename)\n",
    "        print(\"saved file {}\".format(filename))\n",
    "    \n",
    "    # train with l1 regularization.\n",
    "    # start from pretrained model with no_covaraince. \n",
    "    # This will make training faster\n",
    "    for l2 in l2_strengths: \n",
    "        gr.partial_load_ckpt(filename=filename_no_covariate)\n",
    "        print(\"l2 regularization\", l2)\n",
    "        gr.train(\n",
    "            dataset=train_dataset,\n",
    "            n_steps=n_train_steps_from_pretrained,\n",
    "            print_frequency=100,\n",
    "            use_covariates=True,\n",
    "            l1_regularization_strength=None,\n",
    "            l2_regularization_strength=l2,\n",
    "            eps_range=(1.0E-5, 1.0E-2),\n",
    "            subsample_size_cells=subsample_size_cells,\n",
    "            subsample_size_genes=None,\n",
    "            from_scratch=True)\n",
    "        filename = os.path.join(gr_ckpt_dir, \"gr_{}_l2_{}.pt\".format(covariate_key, l2))\n",
    "        gr.save_ckpt(filename)\n",
    "        print(\"saved file {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da4cf3-50f8-4651-9971-7ade374f3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "axes[0].plot(no_cov_loss)\n",
    "axes[0].plot(barlow_loss)\n",
    "axes[0].set_ylim(2E7, 2.5E7)\n",
    "\n",
    "axes[1].plot(no_cov_loss)\n",
    "axes[1].plot(barlow_loss)\n",
    "axes[1].set_ylim(2E7, 2.5E7)\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0688a21-77db-44af-b2af-7042a1d2d6d6",
   "metadata": {},
   "source": [
    "# Compare all regressions\n",
    "\n",
    "1. check the loss function converged\n",
    "2. for each covariate_key compute the ration Q_with_covariance vs Q_no_covariance to select the best regularization\n",
    "3. compare across covariate_key\n",
    "\n",
    "REMOVE q_empirical from predict b/c it is misleading\n",
    "I don't like the fact that epsilon is clustered by cell_type. Is it because the model is un-identifiable (both beta0 and eps are K x G). Think about changing model to have eps only being gene dependent. (as by Dylan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11553783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu113.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu113:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
